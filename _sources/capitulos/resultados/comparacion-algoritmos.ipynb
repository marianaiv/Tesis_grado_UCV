{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(comp)=\n",
    "# Comparación de algoritmos\n",
    "El rendimiento de los algoritmos utilizados anteriormente no puede ser comparado directamente mediante las ditribuciones de las predicciones para cada variable. Como vimos en la sección anterior, un algoritmo puede parecer ajustar muy bien a los datos en una variable pero no en otra. Además, en general no es evidente cuál algoritmo obtiene una distribución más cercana a la real. Por esto, utilizamos las métricas explicadas en la {numref}`met` para comparar directamente el rendimiento de los algoritmos.\n",
    "\n",
    "En esta sección se compararán los algoritmos utilizados en la sección anterior, agregando UCluster y GAN-AE. \n",
    "\n",
    "Usualmente, del conjunto R&D se obtendrían las métricas de rendimiento con el fin de configurar los modelos para que realicen la mejor clasificación posible. Sin embargo, en el caso de este trabajo, comparamos el rendimiento de los algoritmos al clasificar un subconjunto del conjunto utilizado para entrenamiento y al clasificar el conjunto BB1.\n",
    "\n",
    "Los resultados presentados en esta sección se obtuvieron utilizando el pipeline de `benchtools`.\n",
    "\n",
    "(comp-RnD)=\n",
    "## Conjunto R&D\n",
    "En la sección anterior, se mostraron las distribuciones predichas de algunas variables utilizando este conjunto con el objetivo de tener una idea general de cómo están clasificando los algoritmos. Las métricas que se mostrarán a continuación están asociadas a esta clasificación.\n",
    "\n",
    "Es necesario acotar que la clasificación realizada por los algoritmos de las LHCO 2020 para el conjunto R&D no se realiza utilizando exactamente el mismo subconjunto de datos utilizado con los demás algoritmos. Aunque es el mismo conjunto de datos, la distribución de los subconjuntos de entrenamiento y prueba varían para los algoritmos de las olimpiadas de acuerdo al código publicado. Sin embargo, la proporción de datos es la misma para todos los métodos.\n",
    "### Métricas numéricas\n",
    "En la {numref}`comp-metricas-num-RnD` se observa una comparación visual de las métricas numéricas: exactitud balanceada, precisión, recuperación y puntaje f1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from benchtools.src.plotools import image_grid\n",
    "\n",
    "# Definimos el path de las imagenes\n",
    "PATH_FIGURES = '../../figuras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-balancedacc-RnD.png','../../figuras/comp-precision-RnD.png',\n",
    "                '../../figuras/comp-recall-RnD.png','../../figuras/comp-f1score-RnD.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-num-RnD', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-num-RnD.png\n",
    "---\n",
    "width: 80%\n",
    "name: comp-metricas-num-RnD\n",
    "---\n",
    "Diagramas de barras de las métricas numéricas obtenidas utilizando el pipeline de `benchtools` para el conjunto R&D. De izquierda a derecha, en la fila superior: exactitud balanceada y precisión. En la fila inferior: recuperación y puntaje f1.\n",
    "```\n",
    "Todos los modelos obtuvieron un puntaje de exactitud balanceada mayor a 70%, lo que se considera alto. Sin embargo, observamos que la precisión y la recuperación varía entre los clasificadores. \n",
    "\n",
    "Los calsificadores supervisados MLP, QDA, GB y RFC obtuvieron altos puntajes de precisión pero bajos puntajes de recuperación. Esto significa que los algoritmos clasifican pocos eventos como señal, pero estas clasificaciones son mayormente correctas. \n",
    "\n",
    "Por otra parte está el modelos de TensorFlow, que obtuvo un menor puntaje de precisión pero un muy alto puntaje de recuperación. Es decir, clasifica mas eventos como señal, clasificando eventos de fondo incorrectamente, pero logra clasificar la mayoría de los eventos de señal con la etiqueta correcta.\n",
    "\n",
    "Los modelos no supervisados KMeans, UCluster y GAN-AE son los modelos con menor precisión pero mayor recuperación. Es decir, están etiquetando muchos eventos de fondo incorrectamente como señal, pero entre los eventos etiquetados como señal se encuentra la mayor parte de los eventos de señal real. \n",
    "\n",
    "La media armónica de estas dos métricas se observa en el gráfico del puntaje f1, donde en general los modelos supervisados obtuvieron puntajes más altos que los modelos no supervisados.\n",
    "\n",
    "El mayor puntaje f1 fue obtenido por RFC, que también tiene el mayor puntaje de precisión. A su vez, el mayor puntaje de exactitud balanceada lo obtuvo el clasificador de TensorFlow, que también posee el mayor puntaje de recuperación.\n",
    "\n",
    "Los menores puntajes fueron obtenidos por UCluster, con la menor precisión y menor puntaje f1, y por MLP, con el menor puntaje de exactitud balanceada y recuperación. \n",
    "\n",
    "Un resumen de los valores numéricos obtenidos se encuentra a continuación.\n",
    "\n",
    "```{table} Métricas numéricas obtenidas con el pipeline de *benchtools* para el conjunto R&D.\n",
    ":name: comp-metricasnumericas-RnD\n",
    "\n",
    "| Classifier                    |   Balanced accuracy |   Precision |   F1 score |   Recall |\n",
    "|:-----------------------------:|:-------------------:|:-----------:|:----------:|:--------:|\n",
    "| TensorflowClassifier          |            0.9136   |   0.5136    |  0.6576    | 0.9136   |\n",
    "| RandomForestClassifier        |            0.7993   |   0.8681    |  0.7151    | 0.6079   |\n",
    "| GradientBoostingClassifier    |            0.7851   |   0.8249    |  0.6828    | 0.5825   |\n",
    "| QuadraticDiscriminantAnalysis |            0.7991   |   0.7315    |  0.6717    | 0.6209   |\n",
    "| MLPClassifier                 |            0.7658   |   0.6700    |  0.6095    | 0.5590   |\n",
    "| KMeans                        |            0.7938   |   0.2528    |  0.3880    | 0.8342   |\n",
    "| GAN-AE                        |            0.7950   |   0.3962    |  0.5391    | 0.8431   |\n",
    "| UCluster                      |            0.8073   |   0.0310    |  0.0595    | 0.8921   |\n",
    "```\n",
    "### Métricas gráficas\n",
    "Las métricas gráficas obtenidas con el pipeline de benchtools son la eficiencia de señal vs. rechazo de fondo, la ROC inversa, la curva precisión recuperación y la mejora significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-rejection-RnD.png','../../figuras/comp-inverseroc-RnD.png',\n",
    "                '../../figuras/comp-precisionrecall-RnD.png','../../figuras/comp-significance-RnD.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-graf-RnD', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a todas las métricas gráficas, el clasificador de TensorFlow es el que tiene un mejor rendimiento, con un AUC de 0.972 y una precisión promedio de 0.847. Seguido de este, se encuentran RFC y GBC en todas las métricas.\n",
    "```{figure} ../../figuras/comp-metricas-graf-RnD.png\n",
    "---\n",
    "width: 90%\n",
    "name: comp-metricas-graf-RnD\n",
    "---\n",
    "Metricas gráficas para la clasificación del conjunto R&D. De izquierda derecha, en la fila superior: eficiencia de señal vs. rechazo de fondo, ROC inversa, y en la fila inferior: precisión-recuperación y significancia.\n",
    "```\n",
    "Del gráfico de eficiencia de señal vs. rechazo de fondo y del de ROC inversa, es difícil determinar cuál de los algoritmos da un mejor resultado entre QDA y MLP y entre GAN-AE y UCluster, debido a que las curvas se cruzan. Si hacemos referencias al AUC, QDA da un mejor resultado que MLP y GAN-AE da un mejor resultado que UCluster. Sin embargo la diferencia entre los puntajes es pequeña. De acuerdo a estas dos métricas, el clasificador con menor rendimiento es KMeans.\n",
    "\n",
    "Si observamos la métrica de precisión-recuperación, y de acuerdo a la precisión promedio, QDA da un resultado mejor que MLP, y GAN-AE un mejor resultado que UCluster, lo que concuerda con las métricas anteriores. Sin embargo, de acuerdo a esta métrica KMeans tiene un mejor resultado que UCluster.\n",
    "\n",
    "Por último, la mejora significativa parece mayor para QDA que para MLP. Entre UCluster y GAN-AE es más complicada la conclusión porque se cruzan múltiples veces. Sin embargo, UCluster parece alcanzar una mejora significativa mayor que la alcanzada por GAN-AE. KMeans posee la menor mejora significativa.\n",
    "\n",
    "En el caso de este trabajo, es de interés conocer qué tan bien funcionan los modelos para separar señal y fondo en conjuntos de datos con algunas variaciones en las distribuciones, como lo es el conjunto BB1.\n",
    "\n",
    "(comp-BB1)=\n",
    "## Conjunto BB1\n",
    "A diferencia de las predicciones realizadas con el cojunto R&D, las predicciones para el conjunto BB1 se hacen sobre todos los eventos, utilizando los modelos entrenados previamente con el 70% del conjunto R&D. Las métricas obtenidas en este apartado proveen una medida más cercana al verdadero rendimiento de los algoritmos para detectar anomalías.\n",
    "\n",
    "### Métricas numéricas\n",
    "En la {numref}`comp-metricas-num-BB1` vemos que las métricas varían con respecto a lo obtenido para el conjunto R&D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-balancedacc-BB1.png','../../figuras/comp-precision-BB1.png',\n",
    "                '../../figuras/comp-recall-BB1.png','../../figuras/comp-f1score-BB1.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-num-BB1', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-num-BB1.png\n",
    "---\n",
    "width: 100%\n",
    "name: comp-metricas-num-BB1\n",
    "---\n",
    "Diagramas de barras de las métricas numéricas obtenidas utilizando el pipeline de `benchtools` para el conjunto BB1. De izquierda a derecha, en la fila superior: exactitud balanceada y precisión. En la fila inferior: recuperación y puntaje f1.\n",
    "```\n",
    "La exactitud balanceada sigue siendo alta para todos los algoritmos. Sin embargo, se observa una disminución más marcada en los clasificadores QDA, GBC y RFC.\n",
    "\n",
    "La precisión disminuyó notablemente para todos los modelos. Para este conjunto, la mayor precisión fue lograda por GBC con un 4% de precisión, contrario a la precisión obtenida para el conjunto R&D, de 82%. Esto implica que los algoritmos clasifican más eventos de fondo incorrectamente, o menos eventos de señal correctamente, en el conjunto BB1.\n",
    "\n",
    "La recuperación aumentó para el clasificador MLP. Para los clasificadores QDA, GBC, RFC disminuyó. para UCluster, GAN-AE, KMeas y el clasificador de TensorFlow, la recuperación se mantuvo cercana o sobre el 80%. La baja precisión y alta recuperación indica que los modelos están clasificando muchos eventos de fondo como señal. Sin embargo, en estos eventos clasificados como señal logran clasificar la señal real.\n",
    "\n",
    "Debido a la baja precisión, el puntaje f1 se vio afectado y disminuyó notablemente para todos los clasificadores. El clasificador con mayor puntaje es GBC, con un puntaje f1 de 0.05, mientras que en el conjunto R&D obtuvo 0.68. \n",
    "\n",
    "```{table} Métricas numéricas obtenidas con el pipeline de *benchtools* para el conjunto BB1.\n",
    ":name: comp-metricasnumericas-BB1\n",
    "\n",
    "| Classifier                    |   Balanced accuracy |   Precision |    F1 score |   Recall |\n",
    "|:-----------------------------:|:-------------------:|:-----------:|:-----------:|:--------:|\n",
    "| TensorflowClassifier          |            0.8418   | 0.0049      | 0.0096      | 0.8249   |\n",
    "| RandomForestClassifier        |            0.7005   | 0.0362      | 0.0666      | 0.4101   |\n",
    "| GradientBoostingClassifier    |            0.7164   | 0.0367      | 0.0678      | 0.4424   |\n",
    "| QuadraticDiscriminantAnalysis |            0.6894   | 0.0264      | 0.0495      | 0.3909   |\n",
    "| MLPClassifier                 |            0.8143   | 0.0028      | 0.0055      | 0.9005   |\n",
    "| KMeans                        |            0.8094   | 0.0039      | 0.0078      | 0.7854   |\n",
    "| GAN-AE                        |            0.9091   | 0.0201      | 0.0393      | 0.8752   |\n",
    "| UCluster                      |            0.8070   | 0.0002      | 0.0003      | 0.9767   |\n",
    "```\n",
    "### Métricas gráficas\n",
    "Las métricas gráficas también varían con respecto a las obtenidas utilizando el conjunto R&D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-rejection-BB1.png','../../figuras/comp-inverseroc-BB1.png',\n",
    "                '../../figuras/comp-precisionrecall-BB1.png','../../figuras/comp-significance-BB1.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-graf-BB1', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-graf-BB1.png\n",
    "---\n",
    "width: 90%\n",
    "name: comp-metricas-graf-BB1\n",
    "---\n",
    "Metricas gráficas obtenidas para el conjunto BB1. De izquierda derecha, en la fila superior: eficiencia de señal vs. rechazo de fondo, ROC inversa, y en la fila inferior: precisión-recuperación y significancia.\n",
    "```\n",
    "En todos los gráficos, UCluster y KMeans obtuvieron los menores puntajes. De acuerdo al gráfico de eficiencia de señal vs. rechazo de fondo, KMeans tiene un mayor AUC que UCluster. Sin embargo, no es evidente en el gráfico cuál tiene mejor rendimiento porque las líneas se cruzan múltiples veces. Esto también se observa en el gráfico de ROC inversa.\n",
    "\n",
    "De la métrica de precisión recuperación, obtenemos una precisión media de cero para estos clasificadores. En el gráfico de significancia se observa que ambos se encuentran cercanos a un clasificador aleatorio.\n",
    "\n",
    "Por otra parte, la diferencia entre los clasificadores supervisados no es evidente. De acuerdo al AUC, GBC tiene mejor rendimiento que el clasificador de TensorFlow, QDA, RFC y MLP, en este orden. Esto se observa un poco mejor en el gráfico de ROC inversa.\n",
    "\n",
    "En el gráfico de precisión-recuperación, nuevamente se obtiene una mayor precisión promedio para GBC, seguido del clasificador de TensorFlow, RFC, MLP y QDA.\n",
    "\n",
    "Por último, es evidente que GAN-AE tiene un mejor rendimiento en este conjunto de datos de acuerdo a todas las métricas gráficas."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
