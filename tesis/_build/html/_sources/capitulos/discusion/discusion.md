(discusion)=
# Discusión de resultados

En el capítulo anterior, se presentó la clasificación realizada por distintos modelos de aprendizaje automático y la comparación con los algoritmos participantes de las LHCO 2020, UCluster y GAN-AE, descritos en la {numref}`alglhco-ucluster` y la {numref}`alglhco-ganae`, respectivamente. A continuación, se analizarán los resultados obtenidos.

## Clasificación
Como se mencionó anteriormente, los modelos fueron entrenados utilizando un subconjunto del 70% del conjunto R&D. Por lo tanto, los resultados obtenidos para el conjunto R\&D consisten en la clasificación del 30% restante. Al considerar las métricas numéricas para este conjunto ({numref}`comp-metricas-num-RnD`), observamos que el rendimiento de los modelos varía de acuerdo a la métrica, es decir, no existe un único modelo que posea mayores o menores puntajes de acuerdo a todas las métricas. Las métricas bidimensionales coinciden para la mayoría de los modelos, pero hay algunas excepciones, como UCluster y KMeans, que no coinciden en el gráfico de eficiencia de señal vs. rechazo de fondo y en el de precisión-recuperación ({numref}`comp-metricas-graf-RnD`).Como no todas las métricas coinciden, es necesario definir cuáles son de mayor importancia en la tarea específica de clasificación de eventos de señal en HEP. 

Como se discute en {cite}`valassi_2019`, en el problema de clasificación de eventos en HEP los datos son altamente desbalanceados y a nivel cualitativo también existe un desbalance; la clasificación correcta de eventos de fondo (TN) es irrelevante. El considerar esto, implica que cualquier métrica que dependa de TN es de limitada relevancia para comparar los modelos. En la {numref}`met-metricas` y la eq.{eq}`ml-exactitudbalanceada`, vemos que la exactitud balanceada considera la efectividad del clasificador para identificar eventos de fondo, ya que incluye la eficiencia de fondo o especificidad. De las métricas bidimensionales, la curva de eficiencia de señal vs. rechazo de fondo y la curva ROC inversa consideran la eficiencia de señal en alguno de sus ejes y, por ende, el AUC es una métrica basada en la eficiencia de fondo. La curva ROC, además de que incluye los TN, es una métrica no recomendada para tareas de clasificación con datos altamente desbalanceados, debido a que no utiliza ambas columnas de la matriz de confusión{cite}`Fawcett_2004`, es decir, la distribución de clases no afecta la métrica, lo que puede conducir a evaluaciones sobre optimistas.

Teniendo en cuenta lo anterior, entre las métricas numéricas, el puntaje f1 es mejor métrica para este problema de clasificación, y entre las métricas bidimensionales, el gráfico de precisión-recuperación da una evaluación más realista de los modelos. A su vez, son más relevantes las métricas bidimensionales, debido a que poseen un mayor rango de clasificaciones posibles, donde, dependiendo del umbral de decisión, se pueden obtener mejores valores para las métricas numéricas.

En general, en la clasificación del **conjunto R&D** son mejores los resultados de los modelos supervisados que los de los modelos no supervisados, incluyendo UCluster y GAN-AE. Los modelos supervisados obtienen mejores resultados porque poseen mayor información en el entrenamiento, puesto que aprenden patrones de los datos de señal y fondo utilizando las etiquetas para los eventos. De acuerdo al puntaje f1 en la {numref}`comp-metricas-num-RnD`, el modelo con mejor rendimiento es MLP, seguido de RFC, GBC, QDA, el clasificador de TensorFlow, GAN-AE, KMeans y UCluster. Todas las métricas bidimensionales indican que MLP tiene mejor rendimiento, seguido del clasificador de TensorFlow, RFC, GBC, QDA y GAN-AE. KMeans y UCluster difieren de acuerdo al AUC y la precisión promedio, pero la métrica relevante para esta tarea es la precisión promedio, que indica que KMeans tiene mejor rendimiento que UCluster en este conjunto de datos.

Entre los modelos supervisados, las redes neuronales (el clasificador de TensorFlow y MLP) obtienen los mejores resultados para el conjunto R&D. Estos son los modelos más complejos implementados en este trabajo y poseen una gran cantidad de parámetros. Para entrenar estar redes, se requiere un gran volumen de datos y recursos computacionales, pero debido a la cantidad de parámetros entrenados, son capaces de modelar más precisamente los datos. Se suelen utilizar en problemas con datos sin estructura, como los datos de este trabajo porque, debido a su complejidad, son capaces de identificar características relevantes en los datos.

RFC obtuvo resultados similares al modelo de TensorFlow al clasificar el conjunto R&D y obtuvo mejores resultados que GBC. Se ha demostrado que GBC suele tener mejores resultados si se configura cuidadosamente, pero en este trabajo se utilizó la configuración por defecto, lo que puede explicar el menor rendimiento en comparación con RFC. Los modelos que utilizan métodos de ensamble suelen ser una alternativa a las redes neuronales por su rendimiento y bajo uso de recursos computacionales. Estos modelos obtienen buenos resultados en problemas complejos de clasificación binaria y son capaces de utilizar una gran cantidad de datos, porque se entrenan utilizando múltiples subconjuntos de datos.  

QDA es el modelo con menor rendimiento entre los modelos supervisados. Este modelo separa clases utilizando una frontera cuadrática. Similar a los modelos de agrupamiento, este algoritmo obtiene un mejor resultado si las clases se encuentran estructuradas de manera que puedan separarse con funciones cuadráticas, y dada la complejidad de los datos de la topología estudiada en este trabajo, se puede dificultar la clasificación sin un preprocesamiento específico para procurar esta separación, lo que no se realizó en el preprocesamiento de `benchtools`.

Entre los modelos no supervisados, GAN-AE obtuvo el mejor resultado para este conjunto. GAN-AE utiliza un codificador automático que es entrenado para crear muestras sintéticas de los datos. Los codificadores automáticos son utilizados para detección de anomalías porque aprenden la función que reconstruye la mayor cantidad de datos, en este caso el fondo. Al encontrarse datos que no se pueden reconstruir con esta función, son clasificados como anómalos. En contraste, UCluster y KMeans, que obtuvieron el menor rendimiento, son algoritmos de agrupamiento y necesitan estructura en los datos. KMeans utiliza los datos preprocesados por `benchtools`, donde no se intenta crear ninguna estructura particular en los datos. De acuerdo a las distribuciones de los datos discutidas en la {numref}`datospp`, la señal y el fondo se solapan en todas las variables y en algunas son muy similares, de lo que se puede inferir que las clases no están organizadas en grupos, por lo que su clasificación utilizando KMeans no obtiene resultados óptimos. Para mejorar esto, se requiere el estudio de variables nuevas que separen las clases o la creación de un espacio donde las variables se agrupen de acuerdo a estas. UCluster realiza un preprocesamiento de datos que intenta crear una estructura en los datos para realizar el agrupamiento. Sin embargo, puede que este preprocesamiento no sea suficiente para lograr grupos significativos en los datos. El bajo rendimiento de UCluster también puede ser resultado de la configuración utilizada al entrenar y clasificar los eventos. Se usó la configuración por defecto, puesto que la utilizada para obtener los resultados en {cite}`Kasieczka_2021` no se encuentra especificada.

Los resultados obtenidos por las métricas concuerdan con lo observado en las distribuciones de las clasificaciones de este conjunto de datos. De acuerdo a las {numref}`clas-variables-dist`, {numref}`clas-variables-noimp-dist` y {numref}`clas-masa-dist`, y a lo discutido en la {numref}`clas`, el modelo MLP es el que obtiene una clasificación con distribuciones más cercanas a las de los datos reales y KMeans obtiene las distribuciones menos precisas. Estas distribuciones nos permiten tener una idea de cómo están clasificando los modelos de las LHCO 2020. De acuerdo con el puntaje f1, GAN-AE tiene un menor rendimiento que el clasificador de TensorFlow, pero mejor rendimiento que KMeans, por lo que se espera que la clasificación con GAN-AE obtenga distribuciones de las variables más cercanas a las de los datos reales que las obtenidas con KMeans, pero menos precisas que las obtenidas con el clasificador de TensorFlow. Igualmente, UCluster tiene un menor puntaje f1 que KMeans, por lo que se espera que las distribuciones obtenidas por la clasificación de UCluster sean menos parecidas a las reales que las obtenidas por KMeans.

La clasificación del **conjunto BB1** fue, para todos los modelos, menos exitosa que la clasificación del conjunto R&D. Principalmente, porque se utilizaron variables dependientes de la masa de la partícula de nueva física en el entrenamiento de los modelos. 

Para los modelos implementados en este trabajo, las variables más importantes para la clasificación de eventos, de acuerdo a los algoritmos RFC y GBC ({numref}`clas-feature-imp`), son las variables de subestructura $\tau_{21}$, el $p_T$, de los dos jets principales, $\Delta R$ y el número de hadrones del evento. Que las variables $\tau_{21}$, $\Delta R$ y el número de hadrones del evento sean relevantes, es positivo porque es de interés que los modelos puedan diferenciar la señal del fondo por características que no sean inherentes de una señal en específico. Sin embargo, estas variables varían con la masa de la partícula de nueva física creada en la colisión. Además, son relevantes las variables de $p_T$ de ambos jets, variables que dependen de las masas de las partículas de nueva física, lo que no es deseable si se quiere un modelo que logre generalizar para eventos de física BSM y realizar una búsqueda independiente de las masas de las partículas.

Una distancia angular $\Delta R$ más angosta para la señal, como se evidencia en la {numref}`clas-senal-RnD-BB1`, es característica de los eventos de partículas de nueva física masiva debido a que su creación requiere una mayor transferencia de momento, lo que resulta en jets que son más centrales en los detectores, es decir, distribuciones de $\Delta R$ más angostas que las del fondo. Sin embargo, al aumentar o disminuir la masa de la partícula de nueva física, esta variable es más o menos angosta, respectivamente, acorde a la figura. Asimismo, la clasificación se ve limitada a partículas nuevas con estado final de quarks, de manera que los eventos de señal posean menos hadrones que los de fondo, de acuerdo a la {numref}`rawdata-nhadrones`, y señales cuyos jets posean una estructura de dos o más subjets, que son las que coinciden con un menor valor de $\tau_{21}$. El valor de $\tau_{21}$ también varía con la masa de la partícula de nueva física, siendo este menor para partículas más masivas, porque los subjets de jets provenientes de partículas producto de colisiones más energéticas se encuentran más cercanos al eje principal del jet. Aunque un mayor $p_T$ de los jets de señal es característica de una partícula de nueva física masiva, puesto que requiere mayor transferencia de momento, el valor exacto es dependiente de la masa de la partícula, a mayores masas, mayor será el valor de $p_T$. Esto puede representar limitaciones al clasificar conjuntos de datos con distintas distribuciones de masa, como el conjunto BB1.

Las variables menos discriminantes son $\phi$ y $\eta$ de ambos jets, que son las que presentan menos separación entre señal y fondo de acuerdo a la {numref}`datospp-vareq-RnD`. La variable $E$ también se encuentra entre las menos relevantes. Esto se puede deber a que esta variable está correlacionada con $p_T$, pero las distribuciones de $p_T$ de señal y fondo tiene un menor grado de superposición que las distribuciones de $E$, por lo que son más útiles para distinguir entre clases.

Las variables más relevantes coinciden para ambos modelos y dan un indicio de los criterios de clasificación de otros modelos. Sin embargo, no significa que estas sean las variables más relevantes para todos los modelos, porque los puntajes para cada variable se obtienen de acuerdo al algoritmo utilizado. De hecho, aunque las variables más relevantes son similares para RFC y GBC, RFC da una mayor valoración a la variable de subestructura $\tau_{21}$ de ambos jets, mientras que la variable más relevante para GBC es el $p_T$ del jet secundario. Además, modelos no supervisados como KMeans no funcionan de acuerdo a la importancia de las variables, sino que clasifican de acuerdo a la estructura interna de las mismas, y utilizan todas las variables para ello.

GAN-AE también hace uso del $p_T$ de los jets, $E$ y además utiliza variables de masa, que son parte de las variables más relevantes para la clasificación realizada por este modelo según {cite}`Vaslin_2020`. UCluster utiliza $\Delta R$ y variables del $pT$ de los constituyentes. Además, el conjunto tiene menor proporción de eventos de señal, lo que aumenta la probabilidad de realizar clasificaciones erróneas. 

Según el puntaje f1 al clasificar el conjunto BB1 ({numref}`comp-metricasnumericas-BB1`), el modelo que logró el mejor resultado es GBC, seguido de RFC, QDA, GAN-AE, el clasificador de TensorFlow, KMeans, MLP y UCluster. Al igual que en la clasificación del conjunto R&D, un modelo supervisado logró una mejor clasificación que los modelos no supervisados. Sin embargo, según las métricas bidimensionales ({numref}`comp-metricas-graf-BB1`), GAN-AE tiene mejor rendimiento que todos los modelos y UCluster es el que posee puntajes más bajos. Según la precisión promedio, después de GAN-AE se encuentra GBC, el clasificador de TensorFlow, QDA, MLP, RFC, KMeans y UCluster.

Para este conjunto de datos, el rendimiento de GAN-AE es mejor que el de los demás modelos debido al uso del codificador automático, que permite que el modelo tenga una mayor capacidad de generalización al hallar eventos de señal porque, como se mencionó anteriormente, optimiza aprender una función para modelar la mayor cantidad de datos, contrario a los modelos supervisados, que optimizan el modelo para aprender la señal y el fondo. Además, la señal del conjunto BB1 presenta un mayor grado de separación del fondo, por lo que es más anómala para el modelo. En general, todos los modelos supervisados tienen un rendimiento similar, que es bastante menor al rendimiento al clasificar el conjunto R&D, resultado de utilizar en el entrenamiento variables que varían con la masa de la partícula de nueva física. Al clasificar el conjunto BB1, los modelos supervisados obtienen distribuciones para las variables similares a las distribuciones de las variables del conjunto R&D. Esto se evidencia en la {numref}`clas-masa-dist-BB1`, donde se observa que la masa invariante que resulta de la clasificación del conjunto BB1 es más próxima a la del conjunto R&D. Como las señales son similares, y las masas cercanas, los modelos logran clasificar eventos del conjunto BB1, pero no están generalizando para este conjunto, por lo que los resultados son menos precisos. Los modelos con menor rendimiento al clasificar este conjunto son KMeans y UCluster. Esto se debe a que, además de que los datos no poseen estructura interna, como se discutió anteriormente, se utilizaron variables dependientes de la masa en el entrenamiento de los modelos. Para que los modelos tengan mejor rendimiento al clasificar el conjunto BB1, se desea utilizar, idealmente, variables que no varíen al variar la masa de la partícula de nueva física, o cuya variación sea mínima. Por ejemplo, se podrían utilizar las estudiadas en {cite}`ATL-PHYS-PUB-2018-014`, donde se plantean una serie de variables decorrelacionadas de la masa de las partículas. 

Del resultado al clasificar el conjunto BB1, notamos que un modelo no supervisado puede ser mejor distinguiendo entre clases debido al método utilizado, en este caso, a que prioriza modelar el fondo, incluso a pesar de utilizar variables dependientes de la masa para el entrenamiento y la clasificación. Esto da a entender que, aunque los modelos supervisados son mejores clasificando eventos con variables que tengan distribuciones iguales a las de los datos con los que fueron entrenados, al momento de generalizar para realizar búsquedas libres de modelo donde no se conocen las masas de las partículas, los modelos no supervisados pueden tener mejor rendimiento.

De las distribuciones obtenidas de la clasificación del conjunto BB1 ({numref}`clas-variables-dist-BB1` y {numref}`clas-variables-noimp-dist-BB1`), no es evidente cuál algoritmo realiza una mejor clasificación. Al comparar con los modelos de las LHCO 2020, según el puntaje f1, GAN-AE obtiene una distribución de señal con mejor separación de clases que el modelo de TensorFlow, pero menor que QDA. UCluster obtiene distribuciones con una habilidad para separar clases menor que las obtenidas con el modelo MLP.

## Reproducibilidad
A nivel de reproducibilidad, el material publicado de ambos modelos fue sencillo de utilizar. 

El preprocesamiento de los datos para UCluster se logra directamente siguiendo las instrucciones dadas por los autores. El problema principal para reproducir los resultados de este modelo es que la información del ambiente computacional no estaba disponible, específicamente, de las versiones de las librerías utilizadas. Además, para el entrenamiento y clasificación hay varias configuraciones posibles. Las configuraciones utilizadas para obtener los resultados en {cite}`Kasieczka_2021` no se especifican, por lo que se utilizó la configuración por defecto.

Para GAN-AE, el preprocesamiento implicó algunas modificaciones al código para que funcionara correctamente. Entre la información proporcionada para reproducir los resultados, tampoco se incluye información sobre las versiones de las librerías utilizadas, lo que dificulta la utilización del código. También se tuvo que escribir un código aparte para realizar la clasificación del conjunto BB1 con etiquetas, ya que el código publicado no era adaptable para esto.

El análisis de la reproducibilidad de los modelos de las LHCO 2020 inspiró gran parte de las consideraciones de reproducibilidad tomadas en este trabajo. Para reproducir los resultados de los modelos surgió la necesidad de que estos cumplieran con las características mencionadas en la {numref}`alglhco-rep`. Estas características se aplicaron al paquete de software `benchtools`. En particular, se consideró que debía ser configurable, de manera que pueda ser utilizado para comparar los resultados de cualquier modelo con los modelos base planteados en este trabajo. Para que sea configurable y reusable por otros, se agregó información sobre los pasos a seguir para obtener el resultado, considerando que debe haber información sobre el ambiente computacional, el código debe ser libre y estar comentado para que otras personas puedan entenderlo, y debe incluir una licencia con información sobre bajo qué condiciones se puede reusar y modificar la información publicada. Esto se encuentra explicado con mayor detalle en el [repositorio de benchtools](https://github.com/marianaiv/benchtools) y en el [repositorio de este documento](https://github.com/marianaiv/tesis_grado_UCV).