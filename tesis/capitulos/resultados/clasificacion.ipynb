{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(clas)=\n",
    "# Clasificación de eventos\n",
    "Para comparar los algoritmos de las LHCO 2020 utilizamos como base algunos algoritmos sencillos ya implementados en librerías como `scikit-learn`{cite}`scikit-learn` y uno programado usando `TensorFlow`{cite}`tensorflow2015-whitepaper`. \n",
    "\n",
    "En esta sección se observarán algunas de las característica de la clasificación realizada con estos algoritmos. Los modelos utilizados son los presentados en la {numref}`clas-alg`, explicados en la {numref}`alg`.:\n",
    "\n",
    "```{table} Algoritmos utilizados para comparación\n",
    ":name: clas-alg\n",
    "\n",
    "|      Nombre                      | Implementación | Tipo                                             |\n",
    "|:--------------------------------:|:--------------:|:------------------------------------------------:|\n",
    "|Random Forest Classifier (RFC)    | `scikit-learn` | [Bosque aleatorio](alg-bosques)                  |\n",
    "|Gradient Boosting Classifier (GBC)| `scikit-learn` | [Clasificador del gradiente del impulso](alg-gbc)|\n",
    "|Quadratic Discriminant Analysis (QDA) | `scikit-learn` | [Análisis de discriminante cuadrático](alg-qda)  | \n",
    "|MLP Classifier                    | `scikit-learn` | [Red neuronal](alg-neural)                       |\n",
    "|Tensorflow Classifier             | `tensorflow`   | [Red neuronal](alg-neural)                       |\n",
    "| KMeans                           | `scikit-learn` | [K-means](alg-kmeans)                            |\n",
    "```\n",
    "\n",
    "(clas-RnD)=\n",
    "## Conjunto R&D\n",
    "Los datos del conjunto R&D se dividieron 70% en un conjunto de entrenamiento y 30% en uno de prueba. A continuación se mostrará la importancia de las variables para la clasificación según algunos modelos y se observarán las distribuciones predichas por los modelos para algunas variables utilizando el conjunto de prueba.\n",
    "\n",
    "### Importancia de las características\n",
    "De los modelos en la {numref}`clas-alg`, RFC y GBC permiten conocer cuáles de las características de los eventos fueron las variables más relevantes. Esto algoritmos asignan puntajes a las variables de acuerdo a su importancia para la clasificación. Un gráfico de estos puntajes se observa en la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "A continuación, realizaremos el entrenamiento de los modelos y la clasificación de los datos de prueba. Las celdas siguientes preparan los datos, entrenan los modelos y realizan la clasificación utilizando funciones de `benchtools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "# De scikit-learn importamos herramientas\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Y los clasificadores\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Lo necesario para construir el modelo de tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Funciones de benchtools\n",
    "from benchtools.src.plotools import pred_test_hist, image_grid\n",
    "from benchtools.src.clustering import build_features\n",
    "from benchtools.src.datatools import separate_data\n",
    "from benchtools.scripts.run import TensorflowClassifier, training, evaluate\n",
    "from benchtools.src.metrictools import rejection_plot, precision_recall_plot\n",
    "\n",
    "# Definimos semillas para la reproducibilidad\n",
    "tf.random.set_seed(125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Datos a utilizar\n",
    "path_data = \"../../../datos/events_anomalydetection.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file with that name already exists\n"
     ]
    }
   ],
   "source": [
    "# Esta celda se corre una vez para pre-procesar los datos\n",
    "# Una vez que el archivo existe no vuelve a correr\n",
    "build_features(path_data=path_data, nbatch=11, outname='RnD-1100000', outdir='../../../datos/', chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda preparamos los datos para utilizar los algoritmos\n",
    "# Separamos los datos en conjuntos de entrenamiento y prueba\n",
    "df_RnD = pd.read_csv('../../../datos/RnD-1100000.csv')\n",
    "X, y = separate_data(df_RnD, standarize=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # 70% training y 30% test\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_train_m = X_train.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "X_test_m = X_test.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas de los conjuntos de entrenamiento y prueba\n",
    "X_train.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "X_test.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Listamos los clasificadores a utilizar\n",
    "# En conjunto con el scaler\n",
    "classifiers = [(MinMaxScaler(feature_range=(-1,1)), TensorflowClassifier(input_shape = [X_train.shape[1]])),\n",
    "                (StandardScaler(), RandomForestClassifier(random_state=1)),\n",
    "                (RobustScaler(), GradientBoostingClassifier(random_state=4)),\n",
    "                (RobustScaler(), QuadraticDiscriminantAnalysis()), \n",
    "                (StandardScaler(), MLPClassifier(random_state=7)),\n",
    "                (StandardScaler(), KMeans(n_clusters=2, random_state=15))\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 14)               56        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               7680      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,113\n",
      "Trainable params: 1,063,965\n",
      "Non-trainable params: 5,148\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "1429/1429 [==============================] - 123s 85ms/step - loss: 0.1582 - binary_accuracy: 0.9432 - val_loss: 0.1341 - val_binary_accuracy: 0.9521\n",
      "Epoch 2/200\n",
      "1429/1429 [==============================] - 120s 84ms/step - loss: 0.1214 - binary_accuracy: 0.9552 - val_loss: 0.1276 - val_binary_accuracy: 0.9537\n",
      "Epoch 3/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1177 - binary_accuracy: 0.9564 - val_loss: 0.1317 - val_binary_accuracy: 0.9495\n",
      "Epoch 4/200\n",
      "1429/1429 [==============================] - 134s 94ms/step - loss: 0.1150 - binary_accuracy: 0.9574 - val_loss: 0.1287 - val_binary_accuracy: 0.9506\n",
      "Epoch 5/200\n",
      "1429/1429 [==============================] - 139s 97ms/step - loss: 0.1134 - binary_accuracy: 0.9581 - val_loss: 0.1262 - val_binary_accuracy: 0.9529\n",
      "Epoch 6/200\n",
      "1429/1429 [==============================] - 127s 89ms/step - loss: 0.1124 - binary_accuracy: 0.9583 - val_loss: 0.1337 - val_binary_accuracy: 0.9504\n",
      "Epoch 7/200\n",
      "1429/1429 [==============================] - 160s 112ms/step - loss: 0.1113 - binary_accuracy: 0.9589 - val_loss: 0.1642 - val_binary_accuracy: 0.9406\n",
      "Epoch 8/200\n",
      "1429/1429 [==============================] - 141s 98ms/step - loss: 0.1101 - binary_accuracy: 0.9593 - val_loss: 0.1627 - val_binary_accuracy: 0.9396\n",
      "Epoch 9/200\n",
      "1429/1429 [==============================] - 142s 99ms/step - loss: 0.1092 - binary_accuracy: 0.9597 - val_loss: 0.1537 - val_binary_accuracy: 0.9420\n",
      "Epoch 10/200\n",
      "1429/1429 [==============================] - 139s 97ms/step - loss: 0.1086 - binary_accuracy: 0.9597 - val_loss: 0.1562 - val_binary_accuracy: 0.9410\n",
      "Epoch 11/200\n",
      "1429/1429 [==============================] - 126s 88ms/step - loss: 0.1081 - binary_accuracy: 0.9603 - val_loss: 0.1807 - val_binary_accuracy: 0.9294\n",
      "Epoch 12/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1068 - binary_accuracy: 0.9605 - val_loss: 0.1875 - val_binary_accuracy: 0.9319\n",
      "Epoch 13/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1064 - binary_accuracy: 0.9607 - val_loss: 0.1865 - val_binary_accuracy: 0.9292\n",
      "Epoch 14/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1054 - binary_accuracy: 0.9610 - val_loss: 0.1881 - val_binary_accuracy: 0.9262\n",
      "Epoch 15/200\n",
      "1429/1429 [==============================] - 112s 79ms/step - loss: 0.1048 - binary_accuracy: 0.9613 - val_loss: 0.1992 - val_binary_accuracy: 0.9256\n",
      "Epoch 16/200\n",
      "1429/1429 [==============================] - 114s 80ms/step - loss: 0.1042 - binary_accuracy: 0.9615 - val_loss: 0.1999 - val_binary_accuracy: 0.9231\n",
      "Epoch 17/200\n",
      "1429/1429 [==============================] - 123s 86ms/step - loss: 0.1038 - binary_accuracy: 0.9618 - val_loss: 0.2087 - val_binary_accuracy: 0.9234\n",
      "Epoch 18/200\n",
      "1429/1429 [==============================] - 123s 86ms/step - loss: 0.1029 - binary_accuracy: 0.9620 - val_loss: 0.1948 - val_binary_accuracy: 0.9237\n",
      "Epoch 19/200\n",
      "1429/1429 [==============================] - 124s 87ms/step - loss: 0.1028 - binary_accuracy: 0.9620 - val_loss: 0.2100 - val_binary_accuracy: 0.9209\n",
      "Epoch 20/200\n",
      "1429/1429 [==============================] - 118s 83ms/step - loss: 0.1019 - binary_accuracy: 0.9624 - val_loss: 0.2363 - val_binary_accuracy: 0.9182\n",
      "Epoch 21/200\n",
      "1429/1429 [==============================] - 145s 101ms/step - loss: 0.1017 - binary_accuracy: 0.9626 - val_loss: 0.2136 - val_binary_accuracy: 0.9201\n",
      "Epoch 22/200\n",
      "1429/1429 [==============================] - 211s 148ms/step - loss: 0.1010 - binary_accuracy: 0.9626 - val_loss: 0.1894 - val_binary_accuracy: 0.9244\n",
      "Epoch 23/200\n",
      "1429/1429 [==============================] - 203s 142ms/step - loss: 0.1008 - binary_accuracy: 0.9630 - val_loss: 0.1902 - val_binary_accuracy: 0.9211\n",
      "Epoch 24/200\n",
      "1429/1429 [==============================] - 196s 137ms/step - loss: 0.1001 - binary_accuracy: 0.9630 - val_loss: 0.2122 - val_binary_accuracy: 0.9214\n",
      "Epoch 25/200\n",
      "1429/1429 [==============================] - 198s 139ms/step - loss: 0.0998 - binary_accuracy: 0.9632 - val_loss: 0.1904 - val_binary_accuracy: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:29:46<00:00, 897.80s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved\n"
     ]
    }
   ],
   "source": [
    "# Con esta función entrenamos los modelos\n",
    "# Solo hace falta correrla una vez\n",
    "training(X_train, y_train, classifiers, '../../../datos', 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:45<00:00, 17.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# En esta celda cargamos los modelos entrenados\n",
    "models = []\n",
    "\n",
    "# Cargamos el algoritmo entrenado de tensorflow\n",
    "tf_model = load_model(os.path.join('../../../datos','tf_model_{}.h5'.format('log')))\n",
    "models.append(('TensorflowClassifier', tf_model))\n",
    "\n",
    "# Cargamos los algoritmos entrenados de scikit-learn\n",
    "with open(os.path.join('../../../datos',\"sklearn_models_{}.pckl\".format('log')), \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            models.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Evaluamos\n",
    "clfs = evaluate(X_test, y_test, models ,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las características más importantes para los modelos\n",
    "\n",
    "# Obtenemos las características más importantes\n",
    "# models[x][y] : x = 1(random forest), 2(gradient boosting); y = 0(nombre del modelo), 1(modelo entrenado) \n",
    "fi_rf = models[1][1].steps[1][1].feature_importances_.tolist()\n",
    "fi_gb = models[2][1].steps[1][1].feature_importances_.tolist()\n",
    "\n",
    "# Redondeamos los puntajes\n",
    "weights = [fi_rf, fi_gb]\n",
    "weights = [[ round(elem, 3) for elem in weight ] for weight in weights]\n",
    "# Obtenemos los nombres de los modelos\n",
    "names_fi = [models[1][0], models[2][0]]\n",
    "# Obtenemos los nombres de las características\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "# Juntamos los puntajes con las características en tuplas\n",
    "importance = {}\n",
    "ii = 0\n",
    "for weight in weights:\n",
    "    f_i = list(zip(features, weight))\n",
    "    importance[names_fi[ii]] = f_i\n",
    "    ii +=1\n",
    "\n",
    "# Graficamos en un bucle \n",
    "colors=['darkorange', 'green']\n",
    "lista_images = []\n",
    "ii = 0\n",
    "for name, scores in importance.items():\n",
    "\n",
    "    # Ordenamos de menor a mayor\n",
    "    scores.sort(key=lambda x: x[1], reverse=False) \n",
    "\n",
    "    # Salvamos los nombres y su puntaje separados\n",
    "    # y revertimos las tuplas para tener de mayor a menor puntaje \n",
    "    features = list(zip(*scores))[0]\n",
    "    score = list(zip(*scores))[1]\n",
    "    x_pos = np.arange(len(features)) \n",
    "\n",
    "    # Graficamos\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    plt.barh(x_pos, score,align='center', color = colors[ii])\n",
    "    plt.yticks(x_pos, features) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.title('Feature importance: {}'.format(name))\n",
    "    filename = '../../figuras/{}-feature-importance.png'.format(name)\n",
    "    lista_images.append(filename)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "    ii += 1\n",
    "    \n",
    "image_grid(rows=1, columns=2, images=lista_images, name='clas-feature-imp', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-feature-imp.png\n",
    "---\n",
    "name: clas-feature-imp\n",
    "width: 80%\n",
    "---\n",
    "Importancia de las variables utilizadas en el entrenamiento según RFC (izquierda) y GBC (derecha).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características más relevantes para ambos clasificadores son la variable de subestructura $\\tau_{21}$ y el $p_T$ de los jets. El número de hadrones de los eventos también es una variable relevante para la clasificación. En general, son de importancia las características que presentan distribuciones diferentes para señal y fondo.\n",
    "### Distribuciones predichas\n",
    "De la clasificación con los distintos modelos, se pueden obtener las distribuciones de las variables para observar qué tan cercana es la clasificación a los datos reales. En la {numref}`clas-variables-dist` observamos las distribuciones reales y predichas para las variables más importante según la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist.png\n",
    "---\n",
    "name: clas-variables-dist\n",
    "width: 90%\n",
    "---\n",
    "Distribución reales y predichas de algunas de las variables más importantes para la clasificación usando el conjunto prueba R&D. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $p_T$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "Vemos que en general, los modelos predicen el fondo con bastante precisión. La distinción entre señal y fondo es lograda en gran medida por los modelos supervisados. Particularmente, vemos que el clasificador de Tensorflow está sobreestimando el fondo y subestimando la señal en todas las variables. Al contrario, RFC, GBC y QDA sobreestiman la señal y subestiman el fondo. El clasificador MLP parece clasificar las clases con mayor precisión. El único modelo no-supervisado, Kmeans, logra separar algunos eventos de señal según los gráficos de $p_T$ y de $\\tau_{12}$. En el gráfico de número de hadrones vemos que no logra diferenciar entre clases.\n",
    "\n",
    "Al graficar algunas de las variables con menor importancia según la {numref}`clas-feature-imp`, se observa que los modelos supervisados logran separar señal y fondo ({numref}`clas-variables-noimp-dist`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist.png\n",
    "---\n",
    "name: clas-variables-noimp-dist\n",
    "width: 90%\n",
    "---\n",
    "Distribución de algunas de las variables menos relevantes para la clasificación. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "El modelo de TensorFlow parece ser el más preciso estimando $\\eta$ del jet principal, variable para la cual el clasificador MLP logra separar señal y fondo pero la distribución de la señal predicha está corrida a la izquierda. Nuevamente, Kmeans parece diferenciar ligeramente entre clases en algunas variables. En la variable $\\eta$ vemos que no logra distinguir entre señal y fondo.\n",
    "\n",
    "En la {numref}`clas-masa-dist` podemos ver la predicción de la variable de masa invariante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "    \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist.png\n",
    "---\n",
    "name: clas-masa-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante. En la fila superior, de izquierda a derecha, las predicciones de: Tensorflow Classifier, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "Las variables de masa no fueron utilizadas para entrenamiento. Sin embargo, los modelos supervisados logran obtener distribuciones cercanas, lo que indica que están realizando correctamente la clasificación. \n",
    "\n",
    "El modelo de TensorFlow parece estar subestimando la señal. Los demás modelos supervisados parecen sobreestimar la señal. Kmeans obtiene un pico para la señal correctamente clasificado, pero es evidente que está clasificando algunos eventos de fondo como señal, como se puede notar en el gráfico al observar las distribuciones entre 4000 y 6000 GeV.\n",
    "\n",
    "(clas-BB1)=\n",
    "## Conjunto BB1\n",
    "El conjunto BB1 se clasifica completamente, utilizando los modelos entrenados con el 70% del conjunto R&D.\n",
    "### Reconstrucción de las variables\n",
    "Las distribuciones de las variables más relevantes según la {numref}`clas-feature-imp` y las predicciones realizadas con respecto al conjunto BB1, se puede observar en la {numref}`clas-variables-dist-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [05:37<00:00, 56.24s/it] \n"
     ]
    }
   ],
   "source": [
    "# En esta celda preparamos los datos a utilizar por los algoritmos\n",
    "# Separamos los datos variables y label\n",
    "df_BB1 = pd.read_csv('../../../datos/BB1-1000000.csv')\n",
    "X, y = separate_data(df_BB1, standarize=False)\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_m = X.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas\n",
    "X.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "clfs = evaluate(X, y, models ,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-dist-BB1\n",
    "width: 90%\n",
    "---\n",
    "Distribución de las variables más importantes y las predicciones para el conjunto BB1. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $p_T$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "El poder de distinción entre señal y fondo de los modelos disminuye al utilizar el conjunto BB1. Como se puede observar en la {numref}`clas-variables-dist-BB1`, para RFC, GBC y QDA, las distribuciones predichas del fondo son bastante exactas. Sin embargo, no se logra obtener las distribuciones de la señal; vemos distribuciones de señal que se acercan a la distribución de la señal real contaminadas por eventos de fondo.\n",
    "\n",
    "El clasificador de TensorFlow, MLP y KMeans obtienen distribuciones de fondo menos precisas. A su vez, las distribuciones de señal son menos parecidas a las reales. El clasificador de TensorFlow y MLP logran obtener distribuciones del número de hadrones cercanas a las de la señal real, pero para $p_T$ y $\\tau_{21}$ diferencian poco entre señal y fondo. KMeans diferencia más en la variable $p_T$ entre clases, mientras que para $\\tau_{21}$ y el número de hadrones no logra distinción entre señal y fondo.\n",
    "\n",
    "Las distribuciones predichas de las variables menos relevante se encuentran en la {numref}`clas-variables-noimp-dist-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-noimp-dist-BB1\n",
    "width: 90%\n",
    "---\n",
    "Distribución real y predicha de algunas de las variables menos relevantes para la clasificación para el conjunto BB1 . Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "De acuerdo a estas variables, los modelos RFC, GBC y QDA parecen clasificar correctamente una porción significativa de la señal real. \n",
    "\n",
    "MLP y el clasificador de TensorFlow obtienen una distribución cercana de $\\eta$ pero no obtienen la distribución de la señal en $\\Delta R$ y $E$. KMeans obtiene una mejor separación de los eventos en lo que respecta a $E$ pero no diferencia entre señal y fondo en $\\Delta R$ y $\\eta$.\n",
    "\n",
    "Por último, observamos las distribuciones de masa invariante obtenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "    \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist-BB1.png\n",
    "---\n",
    "name: clas-masa-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante y la clasificación del conjunto BB1. En la fila superior, de izquierda a derecha, las predicciones de: Tensorflow Classifier, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "Ninguno de los modelos obtiene la distribución de la señal. RFC y GBC obtienen distribuciones más cercanas a la distribución real de señal y MLP es el modelo que diferencia menos entre señal y fondo para esta variable.\n",
    "\n",
    "Aunque la comparación de distribuciones proporciona un punto de partida para la comparación de los algoritmos, es necesario el uso de métricas, porque no es evidente qué algoritmo está realizando una mejor clasificación de los conjuntos de datos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
