# Introducción
El modelo estándar de física de partículas es considerado una de las teorías más exitosas de la física moderna. Construido durante la última mitad del siglo XX, proporciona la clasificación de las partículas fundamentales y explica sus interacciones. Sin embargo, de esta teoría surgen múltiples preguntas debido a inconsistencias teóricas y experimentales, y se plantean teorías más allá del modelo estándar para resolverlas. 

Desde el hallazgo del bosón de Higgs en 2012, la última partícula predicha por el modelo estándar para la que no se tenía medición experimental, la búsqueda de nueva física es parte del programa principal de múltiples centros de investigación, como el Gran Colisionador de Hadrones (LHC, por sus siglas en inglés), donde se aceleran y colisionan partículas con el objetivo de estudiar diferentes teorías de física de partículas. Han pasado 10 años del hallazgo del bosón de Higgs y la búsqueda de nueva física no ha sido exitosa. En paralelo a esta búsqueda, el LHC se ha mejorado para lograr colisiones más energéticas, lo que implica que se generan eventos de colisión que generan mayor volumen de datos y son más complejos. El análisis de estos experimentos de colisión podría verse limitado por las herramientas que se tengan disponibles para el análisis de los datos, por lo que el desarrollo de nuevas herramientas es parte fundamental de esta búsqueda. En los últimos años se ha estudiado el uso de técnicas de aprendizaje automático como una herramienta que puede ser ideal para enfrentar los retos de estos análisis.

Se han realizado múltiples esfuerzos para investigar y mejorar el uso de aprendizaje automático en física de altas energías, entre los que se encuentran las olimpiadas LHC 2020, una competencia en la que se investigó el uso de técnicas de detección de anomalías para la búsqueda de nueva física. Parte de la idea detrás de este evento fue hacer ciencia de forma abierta y en comunidad, en el que pudieran participar grupos pertenecientes a otras áreas de estudio interesados en el desarrollo de estas herramientas. En las olimpiadas se publicaron tres conjuntos de datos y participaron 18 modelos. Sin embargo, el rendimiento de los algoritmos no es directamente comparable porque no se utilizó una métrica común; solo se pueden comparar los modelos por el resultado obtenido. Esto motivó al planteamiento de este proyecto, con el objetivo de comparar el rendimiento de algoritmos de aprendizaje automático en la búsqueda de nueva física.

En este documento se presentan los resultados de la comparación de algoritmos de aprendizaje automáticos utilizados para buscar partículas de física más allá del modelo estándar en eventos dijet, haciendo uso de datos y algoritmos participantes de las olimpiadas LHC 2020. Específicamente, se comparan dos algoritmos participantes en las olimpiadas con algoritmos implementados en librerías de python, utilizando métricas de rendimiento comúnes en la tarea de clasificación binaria. El análisis general se llevó a cabo utilizando un paquete de software basado en python, `benchtools`, desarrollado para este trabajo con el objetivo de facilitar el manejo de los datos y la comparación directa de algoritmos de clasificación binaria. El paquete incluye múltiples herramientas, entre las que se pueden mencionar: el agrupamiento de los jets y cálculo de variables cinemáticas a partir de los datos proporcionados por las olimpiadas LHC 2020 y el cálculo y graficación de métricas para la comparación de modelos en la búsqueda de anomalías. La exploración de los datos pre-procesados usando `benchtools` y el pre-procesamiento de otros modelos también se encuentra en este trabajo.

En congruencia con la filosofía de las olimpiadas LHC 2020, a largo de este trabajo se tomaron consideraciones sobre la reproducibilidad científica, teniendo presente que el uso de estas herramientas en el área de la investigación es reciente. Los lineamientos para hacer una investigación reproducible se tomaron de [The Turing Way](https://the-turing-way.netlify.app/welcome), un manual para hacer ciencia de datos de manera abierta, ética y colaborativa, y son parte fundamental del desarrollo de este proyecto. Estas consideraciones se evidencian más directamente en los documentos digitales asociados a este trabajo: el [repositorio](https://github.com/marianaiv/benchtools) de `benchtoola`, la herramienta desarrollada para este análisis, y este jupyter book, donde se presenta el análisis final.