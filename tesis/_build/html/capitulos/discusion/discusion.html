
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>6. Discusión de resultados &#8212; Búsqueda de nueva física utilizando técnicas de aprendizaje automático en eventos de múltiples jets</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="7. Conclusión" href="../conclusion/conclusion.html" />
    <link rel="prev" title="5.2. Comparación de algoritmos" href="../resultados/comparacion-algoritmos.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo_ucv.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Búsqueda de nueva física utilizando técnicas de aprendizaje automático en eventos de múltiples jets</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Buscar este libro ..." aria-label="Buscar este libro ..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduccion.html">
   1. Introducción
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../marco-teorico/resumen.html">
   2. Marco teórico
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/modelo-estandar.html">
     2.1. El módelo estándar
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/cromodinamica-cuantica.html">
     2.2. Cromodinámica cuántica
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/mas-alla-del-ms.html">
     2.3. Más allá del modelo estándar
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/reconstruccion-jets.html">
     2.4. Reconstrucción de jets
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/aprendizaje-automatico.html">
     2.5. Aprendizaje automático
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/olimpiadas-LHC.html">
     2.6. El uso del aprendizaje automático y las Olimpiadas LHC 2020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../marco-teorico/reproducibilidad.html">
     2.7. Olimpiadas LHC 2020 y la importancia de la reproducibilidad
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../datos-metodos/resumen.html">
   3. Datos y métodos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../datos-metodos/datos-lhco.html">
     3.1. Conjuntos de datos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datos-metodos/algoritmos-anomalias.html">
     3.2. Algoritmos para detección de anomalías
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datos-metodos/algoritmos-lhco.html">
     3.3. Algoritmos LHCO 2020
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datos-metodos/metricas.html">
     3.4. Métricas de rendimiento
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../datos-metodos/benchtools.html">
     3.5. Paquete benchtools
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../analisis-datos/resumen.html">
   4. Exploración de datos
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis-datos/datos-sin-preprocesar.html">
     4.1. Datos sin pre-procesar
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis-datos/datos-preprocesados.html">
     4.2. Datos pre-procesados
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis-datos/datos-UCluster.html">
     4.3. Datos de UCluster
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../analisis-datos/datos-GAN-AE.html">
     4.4. Datos de GAN-AE
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../resultados/resumen.html">
   5. Resultados
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../resultados/clasificacion.html">
     5.1. Clasificación de eventos
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../resultados/comparacion-algoritmos.html">
     5.2. Comparación de algoritmos
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   6. Discusión de resultados
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../conclusion/conclusion.html">
   7. Conclusión
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../referencias/referencias.html">
   8. Referencias
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Navegación de palanca" aria-controls="site-navigation"
                title="Navegación de palanca" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Descarga esta pagina"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/capitulos/discusion/discusion.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Descargar archivo fuente" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Imprimir en PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/marianaiv/tesis_grado_UCV"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Repositorio de origen"><i
                    class="fab fa-github"></i>repositorio</button></a>
        <a class="issues-button"
            href="https://github.com/marianaiv/tesis_grado_UCV/issues/new?title=Issue%20on%20page%20%2Fcapitulos/discusion/discusion.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Abrir un problema"><i class="fas fa-lightbulb"></i>Tema abierto</button></a>
        <a class="edit-button" href="https://github.com/marianaiv/tesis_grado_UCV/edit/main/tesis/capitulos/discusion/discusion.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edita esta página"><i class="fas fa-pencil-alt"></i>sugerir editar</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Modo de pantalla completa"
        title="Modo de pantalla completa"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contenido
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion">
   6.1. Clasificación
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reproducibilidad">
   6.2. Reproducibilidad
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Discusión de resultados</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contenido </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#clasificacion">
   6.1. Clasificación
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reproducibilidad">
   6.2. Reproducibilidad
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="discusion-de-resultados">
<span id="discusion"></span><h1><span class="section-number">6. </span>Discusión de resultados<a class="headerlink" href="#discusion-de-resultados" title="Enlazar permanentemente con este título">¶</a></h1>
<p>En el capítulo anterior, se presentó la clasificación realizada por distintos modelos de aprendizaje automático y la comparación con los algoritmos participantes de las LHCO 2020, UCluster y GAN-AE, descritos en la <a class="reference internal" href="../datos-metodos/algoritmos-lhco.html#alglhco-ucluster"><span class="std std-numref">Sección 3.3.2</span></a> y la <a class="reference internal" href="../datos-metodos/algoritmos-lhco.html#alglhco-ganae"><span class="std std-numref">Sección 3.3.3</span></a>. A continuación, se analizarán los resultados obtenidos.</p>
<div class="section" id="clasificacion">
<h2><span class="section-number">6.1. </span>Clasificación<a class="headerlink" href="#clasificacion" title="Enlazar permanentemente con este título">¶</a></h2>
<p>Como se mencionó anteriormente, los modelos fueron entrenados utilizando un subconjunto del conjunto R&amp;D. Por lo tanto, los resultados obtenidos para el conjunto R&amp;D consisten en el subconjunto restante. Al considerar las métricas númericas para este conjunto (<a class="reference internal" href="../resultados/comparacion-algoritmos.html#comp-metricas-num-rnd"><span class="std std-numref">Figura 5.9</span></a>), observamos que el rendimiento de los modelos varía de acuerdo a la métrica, es decir, no existe un único modelo que posea mayores o menores puntajes de acuerdo a todas las métricas. Las métricas bidimensionales coinciden para la mayoría de los modelos, pero hay algunas excepciones, como UCluster y KMeans, que no coinciden en el gráfico de eficiencia de señal vs. rechazo de fondo y en el de precisión-recuperación (<a class="reference internal" href="../resultados/comparacion-algoritmos.html#comp-metricas-graf-rnd"><span class="std std-numref">Figura 5.10</span></a>).Como no todas las métricas coinciden, es necesario definir cuáles son de mayor importancia en la tarea específica de clasificación de eventos de señal en HEP.</p>
<p>Como se discute en <span id="id1">[<a class="reference internal" href="../referencias/referencias.html#id86" title="Valassi, Andrea. Binary classifier metrics for optimizing hep event selection. EPJ Web of Conferences, 214:06004, 2019. URL: https://doi.org/10.1051/epjconf/201921406004, doi:10.1051/epjconf/201921406004.">103</a>]</span>, en el problema de clasificación de eventos en HEP los datos son altamente desbalanceados, y a nivel cualitativo también existe un desbalance; la correcta clasificación de eventos de fondo (TN) es irrelevante. El considerar esto implica que cualquier métrica que dependa de TN es de limitada relevancia para comparar los modelos. Si se observa la <a class="reference internal" href="../datos-metodos/metricas.html#met-metricas"><span class="std std-numref">Tabla 3.3</span></a> y la eq.<a class="reference internal" href="../datos-metodos/metricas.html#equation-ml-exactitudbalanceada">(3.16)</a>, vemos que la exactitud balanceada considera la efectividad del clasificador para identificar eventos de fondo, ya que incluye la eficiencia de fondo o especificidad. De las métricas bidimensionales, la curva de eficiencia de señal vs. rechazo de fondo y la curva ROC inversa consideran la eficiencia de señal en alguno de sus ejes y, por ende, el AUC es una métrica basada en la eficiencia de fondo. La curva ROC, además de que incluye los TN, es una métrica no recomendada para tareas de clasificación con datos altamente desbalanceados, debido a que no utiliza ambas columnas de la matriz de confusión<span id="id2">[<a class="reference internal" href="../referencias/referencias.html#id89" title="Tom Fawcett. ROC Graphs: Notes and Practical Considerations for Researchers. Machine Learning, 31:1-38, 01 2004.">106</a>]</span>, es decir, la distribución de clases no afecta la métrica, lo que puede conducir a evaluaciones sobre optimistas.</p>
<p>Teniendo en cuenta lo anterior, entre las métricas númericas, el puntaje f1 es mejor métrica para este problema de clasificación, y entre las métricas bidimensionales, el gráfico de precisión-recuperación da una evaluación más realista de los modelos. A su vez, son más relevantes las métricas bidimensionales, debido a que poseen un mayor rango de clasificaciones posibles, donde, dependiendo del umbral de decisión, se pueden obtener mejores valores para las métricas numéricas.</p>
<p>En general, en la clasificación del <strong>conjunto R&amp;D</strong> son mejores los resultados de los modelos supervisados que los de los modelos no-supervisados, incluyendo UCluster y GAN-AE. Los modelos supervisados obtienen mejores resultados porque poseen mayor información en el entrenamiento, puesto que aprenden patrones de los datos de señal y fondo utilizando las etiquetas para los eventos. De acuerdo al puntaje f1 en la <a class="reference internal" href="../resultados/comparacion-algoritmos.html#comp-metricas-num-rnd"><span class="std std-numref">Figura 5.9</span></a>, el modelo con mejor rendimiento es MLP, seguido de RFC, GBC, QDA, el clasificador de TensorFlow, GAN-AE, KMeans y UCluster. Todas las métricas bidimensionales indican que MLP tiene mejor rendimiento, seguido del clasificador de TensorFlow, RFC, GBC, QDA y GAN-AE. KMeans y UCluster difieren de acuerdo al AUC y la precisión promedio, pero la métrica relevante para esta tarea es la precisión promedio, que indica que KMeans tiene mejor rendimiento que UCluster en este conjunto de datos.</p>
<p>Entre los modelos supervisados, las redes neuronales (el clasificador de TensorFlow y MLP) obtienen los mejores resultados para el conjunto R&amp;D. Estos son los modelos más complejos implementados en este trabajo y poseen una gran cantidad de parámetros. Para entrenar estar redes, se requiere un gran volumen de datos y recursos computacionales, pero debido a la cantidad de parámetros entrenados, son capaces de modelar más precisamente los datos. Se suelen utilizar en problemas con datos sin estructura, como los datos de este trabajo porque, debido a su complejidad, son capaces de identificar características relevantes en los datos.</p>
<p>RFC obtuvo resultados similares al modelo de TensorFlow al clasificar el conjunto R&amp;D y obtuvo mejores resultados que GBC. Se ha demostrado que GBC suele tener mejores resultados si se configura cuidadosamente, pero en este trabajo se utilizó la configuración por defecto, lo que puede explicar el menor rendimiento en comparación con RFC. Los modelos que utilizan métodos de ensamble suelen ser una alternativa a las redes neuronales, por su rendimiento y bajo uso de recursos computacionales. Estos modelos obtienen buenos resultados en problemas complejos de clasificación binaria y son capaces de utilizar una gran cantidad de datos, porque se entrenan utilizando múltiples subconjuntos de datos.</p>
<p>QDA es el modelo con menor rendimiento entre los modelos supervisados. Este modelo separa clases utilizando una frontera cuadrática. Similar a los modelos de agrupamiento, este algoritmo obtiene un mejor resultado si las clases se encuentran estructuradas de manera que puedan separarse con funciones cuadráticas, y dada la complejidad de los datos de la topología estudiada en este trabajo, se puede dificultar la clasificación sin un pre-procesamiento específico para procurar el uso de variables que separen las clases naturalmente, lo que no se realizó en el pre-procesamiento de <code class="docutils literal notranslate"><span class="pre">benchtools</span></code>.</p>
<p>Entre los modelos no-supervisados, GAN-AE obtuvo el mejor resultado para este conjunto. GAN-AE utiliza un codificador automático que es entrenado para crear muestras sintéticas de los datos. Los codificadores automáticos son utilizados para detección de anomalías porque aprenden la función que reconstruye la mayor cantidad de datos, en este caso el fondo. Al encontrarse datos que no se pueden reconstruir con esta función, son clasificados como anómalos. En contraste, UCluster y KMeans, que obtuvieron el mejor rendimiento, son algoritmos de agrupamiento y requieren estructura en los datos. KMeans utiliza los datos pre-procesados por <code class="docutils literal notranslate"><span class="pre">benchtools</span></code>, que no intentan crear ninguna estructura particular en los datos. Los datos no parecen tener una estructura interna natural, de acuerdo a los mapas de correlación (<a class="reference internal" href="../analisis-datos/datos-preprocesados.html#datospp-correlaciones-fondo"><span class="std std-numref">Figura 4.15</span></a> y <a class="reference internal" href="../analisis-datos/datos-preprocesados.html#datospp-correlaciones-senal"><span class="std std-numref">Figura 4.16</span></a>), por lo que la clasificación de estos datos utilizando KMeans no obtiene resultados óptimos. Por otra parte, UCluster realiza un pre-procesamiento de datos que intenta crea una estructura en los datos (un encaje) para realizar el agrupamiento. Sin embargo, puede que este pre-procesamiento no sea suficiente para lograr grupos significativos en los datos. El bajo rendimiento de UCluster también puede ser resultado de la configuración utilizada al entrenar y clasificar los eventos. Se usó la configuración por defecto, puesto que la utilizada para obtener los resultados en <span id="id3">[<a class="reference internal" href="../referencias/referencias.html#id60" title="Gregor Kasieczka et al. The LHC olympics 2020 a community challenge for anomaly detection in high energy physics. Reports on Progress in Physics, 84(12):124201, dec 2021. URL: https://doi.org/10.1088%2F1361-6633%2Fac36b9, doi:10.1088/1361-6633/ac36b9.">72</a>]</span> no se encuentra especificada.</p>
<p>Los resultado obtenidos por las métricas concuerdan con lo observado en las distribuciones de las clasificaciones de este conjunto de datos. De acuerdo a las <a class="reference internal" href="../resultados/clasificacion.html#clas-variables-dist"><span class="std std-numref">Figura 5.2</span></a>, <a class="reference internal" href="../resultados/clasificacion.html#clas-variables-noimp-dist"><span class="std std-numref">Figura 5.3</span></a> y <a class="reference internal" href="../resultados/clasificacion.html#clas-masa-dist"><span class="std std-numref">Figura 5.4</span></a>, y a lo discutido en la <a class="reference internal" href="../resultados/clasificacion.html#clas"><span class="std std-numref">Sección 5.1</span></a>, el modelo MLP es el que obtiene una una clasificación con distribuciones más cercanas a las de los datos reales y KMeans obtiene las distribuciones menos precisas. Estas distribuciones nos permiten tener una idea de cómo están clasificando los modelos de las LHCO 2020. De acuerdo con el puntaje f1, GAN-AE tiene un menor rendimiento que el clasificador de TensorFlow, pero mejor rendimiento que KMeans, por lo que se espera que la clasificación con GAN-AE obtenga distribuciones de las variables más cercanas a las de los datos reales que las obtenidas con KMeans, pero menos precisas que las obtenidas con el clasificador de TensorFlow. Igualmente, UCluster tiene un menor puntaje f1 que KMeans, por lo que se espera que las distribuciones obtenidas por la clasificación de UCluster no distinga correctamente entre clases.</p>
<p>La clasificación del <strong>conjunto BB1</strong> fue, para todos los modelos, menos exitosa que la clasificación del conjunto R&amp;D. Principalmente, porque se utilizaron variables dependientes de la masa de la partícula de nueva física en el entrenamiento de los modelos.</p>
<p>Para los modelos implementados en este trabajo, las variables más importantates para la clasificación de eventos, de acuerdo a los algoritmos RFC y GBC (<a class="reference internal" href="../resultados/clasificacion.html#clas-feature-imp"><span class="std std-numref">Figura 5.1</span></a>), son la variable de subestructura <span class="math notranslate nohighlight">\(\tau_{21}\)</span>, el <span class="math notranslate nohighlight">\(p_T\)</span>, de los dos jets principales, <span class="math notranslate nohighlight">\(\Delta R\)</span> y el número de hadrones del evento. Que las variables <span class="math notranslate nohighlight">\(\tau_{21}\)</span>, <span class="math notranslate nohighlight">\(\Delta R\)</span> y el número de hadrones del evento sean relevantes, es positivo porque nos interesa que los modelos puedan diferenciar la señal del fondo por características que no sean inherentes de una señal en específico. Sin embargo, estas variables varían con la masa de la partícula de nueva física creada. Además, son relevantes las variables de <span class="math notranslate nohighlight">\(p_T\)</span> de ambos jets, variables que dependen de las masas de las partículas de nueva física, lo que no es deseable si se quiere un modelo que logre generalizar para eventos de física BSM y realizar una búsqueda independiente de las masas de las partículas.</p>
<p>Una distancia angular <span class="math notranslate nohighlight">\(\Delta R\)</span> más angosta para la señal, como se observa en <a class="reference internal" href="../resultados/clasificacion.html#clas-senal-rnd-bb1"><span class="std std-numref">Figura 5.6</span></a>, es característica natural de los eventos de partículas de nueva física masiva, debido a que su creación requiere una mayor transferencia de momento, lo que resulta en jets que son más centrales en los detectores, es decir, distribuciones de <span class="math notranslate nohighlight">\(\Delta R\)</span> más angostas que las del fondo. Sin embargo, al aumentar o disminuir la masa de la partícula de nueva física, esta variable es más o menos angosta, respectivamente, como se observa en la figura. Asímismo, la clasificación se ve limitada a partículas nuevas con estado final de quarks, de manera que los eventos de señal posean menos hadrones que los de fondo, como se observa en la <a class="reference internal" href="../analisis-datos/datos-sin-preprocesar.html#rawdata-nhadrones"><span class="std std-numref">Figura 4.3</span></a>, y señales cuyos jets posean una estructura de dos o más subjets, que son las que coinciden con un menor valor de <span class="math notranslate nohighlight">\(\tau_{21}\)</span>. El valor de <span class="math notranslate nohighlight">\(\tau_{21}\)</span> también varía con la masa de la partícula de nueva física, siendo este menor para partículas más masivas, porque los subjets de jets provenientes de partículas producto de colisiones más energéticas se encuentran más cercanos al eje principal del jet. Aunque un mayor <span class="math notranslate nohighlight">\(p_T\)</span> de los jets de señal es característica natural de una partícula de nueva física masiva, puesto que requiere mayor transferencia de momento, el valor exacto es dependiente de la masa de la partícula, a mayores masas, mayor será el valor de <span class="math notranslate nohighlight">\(p_T\)</span>. Esto puede representar limitaciones al clasificar conjuntos de datos con distintas distribuciones de masa, como el conjunto BB1.</p>
<p>Las variables menos discriminantes son <span class="math notranslate nohighlight">\(\phi\)</span> y <span class="math notranslate nohighlight">\(\eta\)</span> de ambos jets, que son las que presentan menos separación entre señal y fondo de acuerdo a la <a class="reference internal" href="../analisis-datos/datos-preprocesados.html#datospp-vareq-rnd"><span class="std std-numref">Figura 4.9</span></a>. La variable <span class="math notranslate nohighlight">\(E\)</span> también se encuentra entre las menos relevantes. Esto se puede deber a que esta variable está correlacionada con <span class="math notranslate nohighlight">\(p_T\)</span>, pero las distribuciones de <span class="math notranslate nohighlight">\(p_T\)</span> de señal y fondo tiene un menor grado de superposisión que las distribuciones de <span class="math notranslate nohighlight">\(E\)</span>, por lo que son más útiles para distinguir entre clases.</p>
<p>Las variables más relevantes coinciden para ambos modelos y da un indicio de los criterios de clasificación de otros modelos. Sin embargo, no significa que estas sean las variables más relevantes para todos los modelos, porque los puntajes para cada variable se obtienen de acuerdo al algoritmo utilizado. De hecho, aunque las variables más relevantes son similares para RFC y GBC, RFC da una mayor valoración a la variable de subestructura <span class="math notranslate nohighlight">\(\tau_{21}\)</span> de ambos jets, mientras que la variable más relevante para GBC es el <span class="math notranslate nohighlight">\(p_T\)</span> del jet secundario. Además, modelos no-supervisados como KMeans no funcionan de acuerdo a la importancia de las variables, sino que clasifican de acuerdo a la estructura interna de las mismas, y utilizan todas las variables para ello.</p>
<p>GAN-AE también hace uso del <span class="math notranslate nohighlight">\(p_T\)</span> de los jets, <span class="math notranslate nohighlight">\(E\)</span> y además utiliza variables de masa, que son parte de las variables más relevantes para la clasificación realizada por este modelo según <span id="id4">[<a class="reference internal" href="../referencias/referencias.html#id111" title="J. Donini, I. Dinu, and L. Vaslin. LHC Olympics Results Report. 2020. Accessed: 09-04-2022. URL: https://www.dropbox.com/s/mml3xk6c4ecd9qr/lhco_lpc%20-%20Ioan%20Dinu.pdf?dl=0.">109</a>]</span>. UCluster utiliza <span class="math notranslate nohighlight">\(\Delta R\)</span> y variables del <span class="math notranslate nohighlight">\(pT\)</span> de los constituyentes. Además, el conjunto tiene menor proporción de eventos de señal, lo que aumenta la probabilidad de realizar clasificaciones erroneas.</p>
<p>Para que los modelos tengan mejor rendimiento al clasificar el conjunto BB1, se deben utilizar, idealmente, variables que no varíen al variar la masa de la partícula de nueva física, o cuya variación sea mínima. Por ejemplo, se podrían utilizar las variables estudiadas en <span id="id5">[<a class="reference internal" href="../referencias/referencias.html#id127" title="ATLAS Collaboration. Performance of mass-decorrelated jet substructure observables for hadronic two-body decay tagging in ATLAS. Technical Report, CERN, Geneva, Jul 2018. URL: http://cds.cern.ch/record/2630973.">112</a>]</span>, donde se plantean una serie de variables decorrelacionadas de la masa de las partículas.</p>
<p>Según el puntaje f1 al clasificar el conjunto BB1 (<a class="reference internal" href="../resultados/comparacion-algoritmos.html#comp-metricasnumericas-bb1"><span class="std std-numref">Tabla 5.3</span></a>), el modelo que logró el mejor resultado es GBC, seguido de RFC, QDA, GAN-AE, el clasificador de TensorFlow, KMeans, MLP y UCluster. Al igual que en la clasificación del conjunto R&amp;D, un modelo supervisado logró una mejor clasificación que los modelos no-supervisados. Sin embargo, según las métricas bidimensionales (<a class="reference internal" href="../resultados/comparacion-algoritmos.html#comp-metricas-graf-bb1"><span class="std std-numref">Figura 5.12</span></a>), GAN-AE tiene mejor rendimiento que todos los modelos y UCluster es el que posee puntajes más bajos. Según la precisión promedio, después de GAN-AE se encuentra GBC, el clasificador de TensorFlow, QDA, MLP, RFC, KMeans y UCluster.</p>
<p>Para este conjunto de datos, el rendimiento de GAN-AE es mejor que el de los demás modelos debido al uso del codificador automático, que permite que el modelo tenga una mayor capacidad de generalización al hallar eventos de señal porque, como se mencionó anteriormente, aprende una función para modelar la mayor cantidad de datos. En general, todos los modelos supervisados tienen un rendimiento similar, que es bastante menor al rendimiento al clasificar el conjunto R&amp;D, resultado de utilizar en el entrenamiento variables que varían con la masa de la partícula de nueva física. Al clasificar el conjunto BB1, los modelos supervisados obtienen distribuciones para las variables similares a las distribuciones de las variables del conjunto R&amp;D. Esto se evidencia en la <a class="reference internal" href="../resultados/clasificacion.html#clas-masa-dist-bb1"><span class="std std-numref">Figura 5.8</span></a>, donde se observa que la masa invariante que resulta de la clasificación del conjunto BB1 es más próxima a la del conjunto R&amp;D. Como las señales son similares, y las masas cercanas, los modelos logran clasificar eventos del conjunto BB1, pero no están generalizando para este conjunto, por lo que los resultados son menos precisos. Los modelos con menor rendimiento al clasificar este conjunto son KMeans y UCluster. Esto se debe a que, además de que los datos no poseen estructura interna, como se discutió anteriormente, se utilizaron variables dependientes de la masa en el entrenamiento de los modelos.</p>
<p>De este resultado, notamos que un modelo no-supervisado puede ser mejor distinguiendo entre clases debido al método utilizado, incluso a pesar de utilizar variables dependientes de la masa para el entrenamiento y la clasificación. Esto da a entender que, aunque los modelos supervisados son mejores clasificando eventos con variables que tengan distribuciones iguales a las de los datos con los que fueron entrenados, en el momento de generalizar, para realizar búsquedas libres de modelo donde no se conocen las masas de las partículas, los modelos no-supervisados pueden tener mejor rendimiento.</p>
<p>De las distribuciones obtenidas de la clasificación del conjunto BB1 (<a class="reference internal" href="../resultados/clasificacion.html#clas-variables-dist-bb1"><span class="std std-numref">Figura 5.5</span></a> y <a class="reference internal" href="../resultados/clasificacion.html#clas-variables-noimp-dist-bb1"><span class="std std-numref">Figura 5.7</span></a>), no es evidente cuál algoritmo realiza una mejor clasificación. Al comparar con los modelos de las LHCO 2020, según el puntaje f1, GAN-AE obtiene una distribución de señal con mejor separación de clases que el modelo de TensorFlow, pero menor que QDA. UCluster obtiene distribuciones con una habilidad para separar clases menor que las obtenidas con el modelo MLP.</p>
</div>
<div class="section" id="reproducibilidad">
<h2><span class="section-number">6.2. </span>Reproducibilidad<a class="headerlink" href="#reproducibilidad" title="Enlazar permanentemente con este título">¶</a></h2>
<p>A nivel de reproducibilidad, el material publicado de ambos modelos fue sencillo de utilizar.</p>
<p>El pre-procesamiento de los datos para UCluster se logra directamente siguiendo las instrucciones dadas por los autores. El problema principal para reproducir los resultados de este modelo es que no proporcionaron información del ambiente computacional, específicamente, de las versiones de las librerías utilizadas. Además, para el entrenamiento y clasificación hay varias configuraciones posibles. Las configuraciones utilizadas para obtener los resultados en <span id="id6">[<a class="reference internal" href="../referencias/referencias.html#id60" title="Gregor Kasieczka et al. The LHC olympics 2020 a community challenge for anomaly detection in high energy physics. Reports on Progress in Physics, 84(12):124201, dec 2021. URL: https://doi.org/10.1088%2F1361-6633%2Fac36b9, doi:10.1088/1361-6633/ac36b9.">72</a>]</span> no se especifican, por lo que se utilizó la configuración por defecto.</p>
<p>Para GAN-AE, el pre-procesamiento implicó algunas modificaciones al código para que funcionara correctamente. Entre la información proporcionada para reproducir los resultados, tampoco se incluye información sobre las versiones de las librerías utilizadas, lo que dificulta la utilización del código. También se tuvo que escribir un código aparte para realizar la clasificación del conjunto BB1 con etiquetas, ya que el codigo publicado no era adaptable para esto.</p>
<p>El análisis de la reproducibilidad de los modelos de las LHCO 2020 inspiró gran parte de las consideraciones de reproducibilidad tomadas en este trabajo. Para reproducir los resultados de los modelos surgió la necesidad de que estos cumplieran con las características mencionadas en la <a class="reference internal" href="../datos-metodos/algoritmos-lhco.html#alglhco-rep"><span class="std std-numref">Sección 3.3.1</span></a>. Estas características se aplicaron al paquete de software <code class="docutils literal notranslate"><span class="pre">benchtools</span></code> En particular, se consideró que debía ser configurable, de manera que pueda ser utilizado para comparar los resultados de cualquier modelo con los modelos base planteados en este trabajo. Para que sea configurable y reusable por otros, se agregó información sobre los pasos a seguir para obtener el resultado, considerando que debe haber información sobre el ambiente computacional, el código debe ser libre y estar comentado para que otras personas puedan entenderlo, y debe incluir una licencia con información sobre bajo qué condiciones se puede reusar y modificar la información publicada. Esto se encuentra explicado con mayor detalle en el <a class="reference external" href="https://github.com/marianaiv/benchtools">repositorio de benchtools</a>.</p>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./capitulos\discusion"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../resultados/comparacion-algoritmos.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title"><span class="section-number">5.2. </span>Comparación de algoritmos</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../conclusion/conclusion.html" title="siguiente página">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title"><span class="section-number">7. </span>Conclusión</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      Por Mariana Vivas, Universidad Central de Venezuela<br/>
    
        &copy; Derechos de autor 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>