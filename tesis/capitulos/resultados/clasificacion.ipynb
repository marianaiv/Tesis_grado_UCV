{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(clas)=\n",
    "# Clasificación de eventos\n",
    "Para comparar los algoritmos de las LHCO 2020, utilizamos como base algunos algoritmos sencillos ya implementados en librerías como `scikit-learn`{cite}`scikit-learn` y uno programado usando `TensorFlow`{cite}`tensorflow2015-whitepaper`. En esta sección, se observarán algunas de las característica de la clasificación realizada con estos algoritmos. Los modelos utilizados son los presentados en la {numref}`clas-alg`, explicados en la {numref}`alg`.\n",
    "\n",
    "```{table} Algoritmos utilizados para comparación\n",
    ":name: clas-alg\n",
    "\n",
    "|      Nombre                          | Implementación | Tipo                                             |\n",
    "|:------------------------------------:|:--------------:|:------------------------------------------------:|\n",
    "|Random Forest Classifier (RFC)        | `scikit-learn` | [Bosque aleatorio](alg-bosques)                  |\n",
    "|Gradient Boosting Classifier (GBC)    | `scikit-learn` | [Clasificador del gradiente del impulso](alg-gbc)|\n",
    "|Quadratic Discriminant Analysis (QDA) | `scikit-learn` | [Análisis de discriminante cuadrático](alg-qda)  | \n",
    "|MLP Classifier                        | `scikit-learn` | [Red neuronal](alg-neural)                       |\n",
    "|Tensorflow Classifier                 | `tensorflow`   | [Red neuronal](alg-neural)                       |\n",
    "| KMeans                               | `scikit-learn` | [K-means](alg-kmeans)                            |\n",
    "```\n",
    "\n",
    "Para el entrenamiento de los modelos y realizar las predicciones se utilizaron las variables descritas en la {numref}`bench-variables`, a excepción de las variables de masa ($m_{jj}$, $m\\_{j_1}$ y $m\\_{j_2}$), con el fin de intentar una clasificación libre de modelo en lo que respecta a la masa de las partículas.\n",
    "\n",
    "(clas-RnD)=\n",
    "## Conjunto R&D\n",
    "Los datos del conjunto R&D se dividieron en conjuntos mutuamente excluyentes: 70% en un conjunto de entrenamiento y 30% en uno de prueba. A continuación se mostrará la importancia de las variables para la clasificación según RFC y GBC y se observarán las distribuciones de los eventos clasificados para algunas variables, utilizando el conjunto de prueba.\n",
    "\n",
    "### Importancia de las características\n",
    "De los modelos en la {numref}`clas-alg`, RFC y GBC permiten conocer cuáles de las variables de los eventos fueron las más relevantes para discriminar entre clases. Esto algoritmos asignan puntajes a las variables de acuerdo a su importancia para la clasificación. Un gráfico de estos puntajes se observa en la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "A continuación, realizaremos el entrenamiento de los modelos y la clasificación de los datos de prueba. Las celdas siguientes preparan los datos, entrenan los modelos y realizan la clasificación utilizando funciones de `benchtools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "# De scikit-learn importamos herramientas\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Y los clasificadores\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Lo necesario para construir el modelo de tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Funciones de benchtools\n",
    "from benchtools.src.plotools import pred_test_hist, image_grid\n",
    "from benchtools.src.clustering import build_features\n",
    "from benchtools.src.datatools import separate_data\n",
    "from benchtools.scripts.run import TensorflowClassifier, training, evaluate\n",
    "from benchtools.src.metrictools import rejection_plot, precision_recall_plot\n",
    "\n",
    "# Definimos semillas para la reproducibilidad\n",
    "tf.random.set_seed(125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Datos a utilizar\n",
    "path_data = \"../../../datos/events_anomalydetection.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file with that name already exists\n"
     ]
    }
   ],
   "source": [
    "# Esta celda se corre una vez para pre-procesar los datos\n",
    "# Una vez que el archivo existe no vuelve a correr\n",
    "build_features(path_data=path_data, nbatch=11, outname='RnD-1100000', outdir='../../../datos/', chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda preparamos los datos para utilizar los algoritmos\n",
    "# Separamos los datos en conjuntos de entrenamiento y prueba\n",
    "df_RnD = pd.read_csv('../../../datos/RnD-1100000.csv')\n",
    "X, y = separate_data(df_RnD, standarize=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # 70% training y 30% test\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_train_m = X_train.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "X_test_m = X_test.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas de los conjuntos de entrenamiento y prueba\n",
    "X_train.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "X_test.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Listamos los clasificadores a utilizar\n",
    "# En conjunto con el scaler\n",
    "classifiers = [(MinMaxScaler(feature_range=(-1,1)), TensorflowClassifier(input_shape = [X_train.shape[1]])),\n",
    "                (StandardScaler(), RandomForestClassifier(random_state=1)),\n",
    "                (RobustScaler(), GradientBoostingClassifier(random_state=4)),\n",
    "                (RobustScaler(), QuadraticDiscriminantAnalysis()), \n",
    "                (StandardScaler(), MLPClassifier(random_state=7)),\n",
    "                (StandardScaler(), KMeans(n_clusters=2, random_state=15))\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "  0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " batch_normalization (BatchN  (None, 14)               56        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               7680      \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               262656    \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 512)              2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,113\n",
      "Trainable params: 1,063,965\n",
      "Non-trainable params: 5,148\n",
      "_________________________________________________________________\n",
      "Epoch 1/200\n",
      "1429/1429 [==============================] - 123s 85ms/step - loss: 0.1582 - binary_accuracy: 0.9432 - val_loss: 0.1341 - val_binary_accuracy: 0.9521\n",
      "Epoch 2/200\n",
      "1429/1429 [==============================] - 120s 84ms/step - loss: 0.1214 - binary_accuracy: 0.9552 - val_loss: 0.1276 - val_binary_accuracy: 0.9537\n",
      "Epoch 3/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1177 - binary_accuracy: 0.9564 - val_loss: 0.1317 - val_binary_accuracy: 0.9495\n",
      "Epoch 4/200\n",
      "1429/1429 [==============================] - 134s 94ms/step - loss: 0.1150 - binary_accuracy: 0.9574 - val_loss: 0.1287 - val_binary_accuracy: 0.9506\n",
      "Epoch 5/200\n",
      "1429/1429 [==============================] - 139s 97ms/step - loss: 0.1134 - binary_accuracy: 0.9581 - val_loss: 0.1262 - val_binary_accuracy: 0.9529\n",
      "Epoch 6/200\n",
      "1429/1429 [==============================] - 127s 89ms/step - loss: 0.1124 - binary_accuracy: 0.9583 - val_loss: 0.1337 - val_binary_accuracy: 0.9504\n",
      "Epoch 7/200\n",
      "1429/1429 [==============================] - 160s 112ms/step - loss: 0.1113 - binary_accuracy: 0.9589 - val_loss: 0.1642 - val_binary_accuracy: 0.9406\n",
      "Epoch 8/200\n",
      "1429/1429 [==============================] - 141s 98ms/step - loss: 0.1101 - binary_accuracy: 0.9593 - val_loss: 0.1627 - val_binary_accuracy: 0.9396\n",
      "Epoch 9/200\n",
      "1429/1429 [==============================] - 142s 99ms/step - loss: 0.1092 - binary_accuracy: 0.9597 - val_loss: 0.1537 - val_binary_accuracy: 0.9420\n",
      "Epoch 10/200\n",
      "1429/1429 [==============================] - 139s 97ms/step - loss: 0.1086 - binary_accuracy: 0.9597 - val_loss: 0.1562 - val_binary_accuracy: 0.9410\n",
      "Epoch 11/200\n",
      "1429/1429 [==============================] - 126s 88ms/step - loss: 0.1081 - binary_accuracy: 0.9603 - val_loss: 0.1807 - val_binary_accuracy: 0.9294\n",
      "Epoch 12/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1068 - binary_accuracy: 0.9605 - val_loss: 0.1875 - val_binary_accuracy: 0.9319\n",
      "Epoch 13/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1064 - binary_accuracy: 0.9607 - val_loss: 0.1865 - val_binary_accuracy: 0.9292\n",
      "Epoch 14/200\n",
      "1429/1429 [==============================] - 122s 85ms/step - loss: 0.1054 - binary_accuracy: 0.9610 - val_loss: 0.1881 - val_binary_accuracy: 0.9262\n",
      "Epoch 15/200\n",
      "1429/1429 [==============================] - 112s 79ms/step - loss: 0.1048 - binary_accuracy: 0.9613 - val_loss: 0.1992 - val_binary_accuracy: 0.9256\n",
      "Epoch 16/200\n",
      "1429/1429 [==============================] - 114s 80ms/step - loss: 0.1042 - binary_accuracy: 0.9615 - val_loss: 0.1999 - val_binary_accuracy: 0.9231\n",
      "Epoch 17/200\n",
      "1429/1429 [==============================] - 123s 86ms/step - loss: 0.1038 - binary_accuracy: 0.9618 - val_loss: 0.2087 - val_binary_accuracy: 0.9234\n",
      "Epoch 18/200\n",
      "1429/1429 [==============================] - 123s 86ms/step - loss: 0.1029 - binary_accuracy: 0.9620 - val_loss: 0.1948 - val_binary_accuracy: 0.9237\n",
      "Epoch 19/200\n",
      "1429/1429 [==============================] - 124s 87ms/step - loss: 0.1028 - binary_accuracy: 0.9620 - val_loss: 0.2100 - val_binary_accuracy: 0.9209\n",
      "Epoch 20/200\n",
      "1429/1429 [==============================] - 118s 83ms/step - loss: 0.1019 - binary_accuracy: 0.9624 - val_loss: 0.2363 - val_binary_accuracy: 0.9182\n",
      "Epoch 21/200\n",
      "1429/1429 [==============================] - 145s 101ms/step - loss: 0.1017 - binary_accuracy: 0.9626 - val_loss: 0.2136 - val_binary_accuracy: 0.9201\n",
      "Epoch 22/200\n",
      "1429/1429 [==============================] - 211s 148ms/step - loss: 0.1010 - binary_accuracy: 0.9626 - val_loss: 0.1894 - val_binary_accuracy: 0.9244\n",
      "Epoch 23/200\n",
      "1429/1429 [==============================] - 203s 142ms/step - loss: 0.1008 - binary_accuracy: 0.9630 - val_loss: 0.1902 - val_binary_accuracy: 0.9211\n",
      "Epoch 24/200\n",
      "1429/1429 [==============================] - 196s 137ms/step - loss: 0.1001 - binary_accuracy: 0.9630 - val_loss: 0.2122 - val_binary_accuracy: 0.9214\n",
      "Epoch 25/200\n",
      "1429/1429 [==============================] - 198s 139ms/step - loss: 0.0998 - binary_accuracy: 0.9632 - val_loss: 0.1904 - val_binary_accuracy: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [1:29:46<00:00, 897.80s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved\n"
     ]
    }
   ],
   "source": [
    "# Con esta función entrenamos los modelos\n",
    "# Solo hace falta correrla una vez\n",
    "training(X_train, y_train, classifiers, '../../../datos', 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [01:45<00:00, 17.52s/it]\n"
     ]
    }
   ],
   "source": [
    "# En esta celda cargamos los modelos entrenados\n",
    "models = []\n",
    "\n",
    "# Cargamos el algoritmo entrenado de tensorflow\n",
    "tf_model = load_model(os.path.join('../../../datos','tf_model_{}.h5'.format('log')))\n",
    "models.append(('TensorflowClassifier', tf_model))\n",
    "\n",
    "# Cargamos los algoritmos entrenados de scikit-learn\n",
    "with open(os.path.join('../../../datos',\"sklearn_models_{}.pckl\".format('log')), \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            models.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Evaluamos\n",
    "clfs = evaluate(X_test, y_test, models ,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las características más importantes para los modelos\n",
    "\n",
    "# Obtenemos las características más importantes\n",
    "# models[x][y] : x = 1(random forest), 2(gradient boosting); y = 0(nombre del modelo), 1(modelo entrenado) \n",
    "fi_rf = models[1][1].steps[1][1].feature_importances_.tolist()\n",
    "fi_gb = models[2][1].steps[1][1].feature_importances_.tolist()\n",
    "\n",
    "# Redondeamos los puntajes\n",
    "weights = [fi_rf, fi_gb]\n",
    "weights = [[ round(elem, 3) for elem in weight ] for weight in weights]\n",
    "# Obtenemos los nombres de los modelos\n",
    "names_fi = [models[1][0], models[2][0]]\n",
    "# Obtenemos los nombres de las características\n",
    "features = X_train.columns.tolist()\n",
    "\n",
    "# Juntamos los puntajes con las características en tuplas\n",
    "importance = {}\n",
    "ii = 0\n",
    "for weight in weights:\n",
    "    f_i = list(zip(features, weight))\n",
    "    importance[names_fi[ii]] = f_i\n",
    "    ii +=1\n",
    "\n",
    "# Graficamos en un bucle \n",
    "colors=['darkorange', 'green']\n",
    "lista_images = []\n",
    "ii = 0\n",
    "for name, scores in importance.items():\n",
    "\n",
    "    # Ordenamos de menor a mayor\n",
    "    scores.sort(key=lambda x: x[1], reverse=False) \n",
    "\n",
    "    # Salvamos los nombres y su puntaje separados\n",
    "    # y revertimos las tuplas para tener de mayor a menor puntaje \n",
    "    features = list(zip(*scores))[0]\n",
    "    score = list(zip(*scores))[1]\n",
    "    x_pos = np.arange(len(features)) \n",
    "\n",
    "    # Graficamos\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    plt.barh(x_pos, score,align='center', color = colors[ii])\n",
    "    plt.yticks(x_pos, features) \n",
    "    plt.xlabel('Feature importance')\n",
    "    plt.title('Feature importance: {}'.format(name))\n",
    "    filename = '../../figuras/{}-feature-importance.png'.format(name)\n",
    "    lista_images.append(filename)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "    ii += 1\n",
    "    \n",
    "image_grid(rows=1, columns=2, images=lista_images, name='clas-feature-imp', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-feature-imp.png\n",
    "---\n",
    "name: clas-feature-imp\n",
    "width: 80%\n",
    "---\n",
    "Importancia de las variables utilizadas en el entrenamiento según RFC (izquierda) y GBC (derecha).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características más importantes para ambos clasificadores son la variable de subestructura $\\tau_{21}$, el $p_T$ de los jets y el número de hadrones de los eventos, y las menos importantes son $\\eta$ y $\\phi$. Esto indica que las variables con mayor separación entre las distribuciones de señal y fondo, como se puede observar en la {numref}`datospp-vardiff-RnD` del capítulo anterior, son mas relevante en el aprendizaje de los modelos. \n",
    "### Distribuciones de eventos clasificados\n",
    "Con la clasificación realizada por los distintos modelos podemos graficar las distribuciones resultantes de los eventos clasificados como señal o fondo y compararlas con las distribuciones reales de los datos de los eventos clasificados. En la {numref}`clas-variables-dist` observamos las distribuciones de los datos reales y clasificados de las variables más importantes según la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist.png\n",
    "---\n",
    "name: clas-variables-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución reales y de la clasificación de algunas de las variables más importantes para la clasificación usando el conjunto prueba R&D. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $p_T$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "En general, las distribuciones obtenidas de la clasificación realizada por los modelos es similar los datos reales. La distinción entre señal y fondo es lograda de forma más precisa por los modelos supervisados, porque poseen más información en sobre los eventos en el momento del aprendizaje, puesto que aprenden utilizando la etiqueta de cada evento. \n",
    "\n",
    "Particularmente, vemos que el clasificador de Tensorflow está subestimando la cantidad de eventos de señal en todas las variables. Esto se evidencia en los picos de las distribuciones de las variables, donde se observa que las distribuciones de los eventos clasificados como señal poseen menor frecuencia de eventos que la señal real. Al contrario, se observa que RFC, GBC y QDA sobreestiman la cantidad de eventos de señal, puesto que en los picos de señal en cada gráfico se observa que las distribuciones de los eventos clasificados como señal son mas frecuentes que los de la señal real. El clasificador MLP parece clasificar con mayor precisión, ya que la señal clasificada es más cercana a la real. El único modelo no-supervisado, Kmeans, logra separar algunos eventos de señal según los gráficos de $p_T$ y de $\\tau_{12}$, pero en el gráfico de número de hadrones vemos que no logra diferenciar entre clases. Esto indica que los eventos de señal predicho están contaminados por eventos de fondo.\n",
    "\n",
    "Al graficar algunas de las variables con menor importancia según la {numref}`clas-feature-imp`, en la {numref}`clas-variables-noimp-dist`, también se evidencia que el clasificador de TensorFlow está subestimando la cantidad de eventos de señal y que RFC, GBC y QDA sobreestiman la cantidad de eventos de señal. Como se mencionó anteriormente, el modelo MLP clasifica más precisamente, lo que también se observa en estas variables, donde las distribuciones de la clasificación son similares a las de los datos reales. Para KMeans, se observa nuevamente que los eventos predichos como señal está contaminados por eventos de fondo, puesto que en el gráfico de $\\eta$ el modelo no distingue entre señal y fondo, y en $\\Delta R$ y $E$ los picos de las distribuciones de los eventos predichos como señal muestran menor frecuencia de eventos que las distribuciones de la señal real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist.png\n",
    "---\n",
    "name: clas-variables-noimp-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución de algunas de las variables menos relevantes para la clasificación. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "En la {numref}`clas-masa-dist` podemos ver las distribuciones de la variable de masa invariante de acuerdo a la clasificacion realizada por los modelos. Las variables de masa no fueron utilizadas para entrenamiento y es de las variables más comunmente utilizadas en la búsqueda de nueva física. En esta variable, se observa que los modelos supervisados obtienen resultados más precisos que el modelo no-supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "    \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist.png\n",
    "---\n",
    "name: clas-masa-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante y la clasificación para el conjunto R&D. En la fila superior, de izquierda a derecha, las predicciones de: Tensorflow Classifier, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "En los modelos supervisados se vuelve a evidenciar lo discutido anteriormente; el modelo de TensorFlow subestima la cantidad de señal y los demás modelos sobreestiman la cantidad de señal. Kmeans obtiene un pico para la señal clasificada de magnitud correcta, pero con baja frecuencia, y es evidente que está clasificando eventos de fondo como señal, como se puede notar en el gráfico al observar las distribuciones de señal y fondo entre 4000 y 6000 GeV.\n",
    "\n",
    "(clas-BB1)=\n",
    "## Conjunto BB1\n",
    "El conjunto BB1 se clasifica completamente, utilizando los modelos entrenados con el 70% del conjunto R&D. Como se mencionó en capítulos anteriores, este conjunto posee una menor proporción de señal, 0.08% del conjunto es señal, y las partículas de nueva física son más masivas.\n",
    "### Distribuciones de eventos clasificados\n",
    "Las distribuciones de las variables más importantes según la {numref}`clas-feature-imp` y la clasificación realizada utilizando el conjunto BB1, se puede observar en la {numref}`clas-variables-dist-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [05:37<00:00, 56.24s/it] \n"
     ]
    }
   ],
   "source": [
    "# En esta celda preparamos los datos a utilizar por los algoritmos\n",
    "# Separamos los datos variables y label\n",
    "df_BB1 = pd.read_csv('../../../datos/BB1-1000000.csv')\n",
    "X, y = separate_data(df_BB1, standarize=False)\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_m = X.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas\n",
    "X.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "clfs = evaluate(X, y, models ,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución de las variables más importantes y las distribuciones de las clasificaciones para el conjunto BB1. Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $p_T$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "El poder de distinción entre señal y fondo de los modelos disminuye al utilizar el conjunto BB1, lo que indica que los modelos no logran generalizar del entrenamiento realizado con el conjunto R&D a otro conjunto de datos con masas distintas para las partículas de BSM. A pesar de haber eliminado la masa para el entrenamiento de los modelos, se utilizaron variables que cambian al variar la masa de las partículas de nueva física del evento. Entre estas variables se encuentra el $p_T$ de los jets, que es mayor para los jets del conjunto BB1 debido a que la partícula de nueva física es más masiva, $\\tau_{21}$, debido a que es más difícil obtener subjets de jets provenientes de colisiones con mayor impulso, y $\\Delta R$, cuya distribución es más angosta para colisiones más energéticas. Dichas variables se encuentran entre las más importantes para realizar la clasificación de acuerdo a {numref}`clas-feature-imp`, lo que puede afectar la clasificación de datos con distintas masas. La diferencia entre las variables mencionadas anteriormente para la señal en los conjuntos R&D y BB1 se encuentra en la {numref}`clas-senal-RnD-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "df_RnD = pd.read_csv('../../../datos/RnD-1100000.csv')\n",
    "df_BB1 = pd.read_csv('../../../datos/BB1-1000000.csv')\n",
    "# Obtenemos los datos de señal en cada conjunto de datos\n",
    "df_RnD_sig = df_RnD.loc[df_RnD.loc[:,'label']==1]\n",
    "df_BB1_sig = df_BB1.loc[df_BB1.loc[:,'label']==1]\n",
    "# Graficamos\n",
    "fig = plt.figure(facecolor='white')\n",
    "ax = fig.add_subplot(1, 1, 1)    \n",
    "# Variables a graficar\n",
    "variables = ['pT_j1', 'tau_21_j1', 'deltaR_j12']\n",
    "list_images = []\n",
    "for variable in variables:\n",
    "    # Creamos los histogramas\n",
    "    df_RnD_sig[variable].plot.hist(bins=50, facecolor='darkorange', alpha=0.4, label='R&D', density=True)\n",
    "    df_BB1_sig[variable].plot.hist(bins=50, facecolor='darkturquoise', alpha=0.4, label='BB1', density=True)   \n",
    "    # Etiquetamos los ejes, colocamos título y leyenda\n",
    "    plt.xlabel(variable)  \n",
    "    plt.ylabel('Events density')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Distribution of {}'.format(variable))\n",
    "    # Guardamos la imagen\n",
    "    filename = './../../figuras/clas-senal-RnD-BB1-{}.png'.format(variable)\n",
    "    plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "    # Creamos una lista con las imagenes creadas\n",
    "    list_images.append(filename)\n",
    "    plt.close('all')\n",
    "\n",
    "# Creamos un grid de las imagenes    \n",
    "image_grid(rows=1, columns=3, images=list_images, name='clas-senal-RnD-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-senal-RnD-BB1.png\n",
    "---\n",
    "name: clas-senal-RnD-BB1\n",
    "width: 100%\n",
    "---\n",
    "Comparación de las distribuciones de señal de las variables $p_T$ del jet principal, $\\tau_{21}$ del jet principal y $\\Delta R$ de los conjuntos de datos R&D y BB1.\n",
    "```\n",
    "Los resultados de la clasificación para las variables más relevantes se pueden visualizar en la {numref}`clas-variables-dist-BB1`. A nivel general, se observa que los modelos no logran realizar correctamente la clasificación de eventos de señal y que dicha clasificación se encuentra contaminada por eventos de fondo. En los gráficos de $p_T$, notamos que los modelos obtienen una distribución corrida hacia la izquierda, es decir, aprendieron a clasificar como señal eventos de jets que poseen menor $p_T$. Igualmente en la variable $\\tau_{21}$, si comparamos con la distribución de esta variable en la {numref}`clas-senal-RnD-BB1`, notamos que los modelos están clasificando para una distribución parecida a la del conjunto R&D. \n",
    "\n",
    "Las distribuciones de las variables menos relevante para la clasificación se encuentran en la {numref}`clas-variables-noimp-dist-BB1`. Las distribuciones de estas variables refuerza lo analizado anteriormente. En general, los modelos clasifican señal con un $\\Delta R$ más ancho y jets menos energéticos, similares a las variables del conjunto R&D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-noimp-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución real y predicha de algunas de las variables menos relevantes para la clasificación para el conjunto BB1 . Cada fila de imágenes representa un clasificador. De arriba a abajo: Tensorflow Classifier, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "Por último, en la {numref}`clas-masa-dist-BB1`, observamos las distribuciones de masa invariante obtenidas para este conjunto de datos. Ninguno de los modelos reconstruye la distribución de la señal. Particularmente, notamos que los picos de señal están corridos hacia menores valores de masa, indicando que los modelos aprendieron a clasificar eventos con menor masa invariante, como la señal del conjunto R&D, a pesar de no haber utilizado las variables de masa en el entrenamiento y la clasificación.\n",
    "\n",
    "En todas las variables el clasificador de TensorFlow y KMeans obtienen las distribuciones de la clasificación menos similares a las reales. Los demás modelos obtuvieron resultados parecidos entre sí, pero en todos es evidente la contaminación de la clasificación de eventos de señal con fondo y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "for model in clfs:\n",
    "    for variable in variables:\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de {}'.format(model.name, variable))\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "    \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist-BB1.png\n",
    "---\n",
    "name: clas-masa-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante y la clasificación del conjunto BB1. En la fila superior, de izquierda a derecha, las predicciones de: Tensorflow Classifier, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "Aunque la comparación de distribuciones proporciona un punto de partida para la comparación de los algoritmos, es necesario el uso de métricas, porque no es evidente cual algoritmo está realizando una mejor clasificación de los conjuntos de datos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
