{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(alglhco)=\n",
    "# Algoritmos LHCO 2020\n",
    "Como se mencionó en la {numref}`lhco`, en las LHCO 2020 participaron 18 algoritmos agrupados dependiendo del tipo de método utilizados. En la {numref}`lhc-participantes` se encuentra un **resumen de los participantes**, con el método, referencias y los datos que analizaron.\n",
    "\n",
    "```{table} Participantes de las LHCO 2020\n",
    ":name: lhc-participantes\n",
    "\n",
    "| Nombre | Método | Referencia | Resultado |\n",
    "|--------|------|------------|-------------|\n",
    "|   VRNN | No supervisado| [Artículo](https://arxiv.org/pdf/2105.09274.pdf), [Presentación](https://indico.cern.ch/event/809820/contributions/3632656/attachments/1971110/3278934/AnomalyScore_LHCOlympics.pdf)| BB1-3 |\n",
    "|   ANODE| No supervisado| [Artículo](https://arxiv.org/pdf/2001.04990.pdf), [Presentación](https://indico.cern.ch/event/809820/contributions/3699483/attachments/1971094/3278905/george_stein_LHCO.pdf)| R&D|\n",
    "| BuHuLaSpa| No supervisado| [Artículo](https://arxiv.org/pdf/2103.06595.pdf)| BB1-3 |\n",
    "|  GAN-AE|    No supervisado| [GitHub](https://github.com/lovaslin/GAN-AE_LHCOlympics), [BumpHunter](https://github.com/lovaslin/pyBumpHunter), [Presentación](https://www.dropbox.com/s/mml3xk6c4ecd9qr/lhco_lpc%20-%20Ioan%20Dinu.pdf?dl=0) | BB1-3 |\n",
    "|     GIS|    No supervisado| [Artículo](https://arxiv.org/pdf/2012.11638.pdf) |BB1|\n",
    "|     LDA|    No supervisado| [GitHub](https://github.com/bmdillon/lda-jet-substructure), [Artículo](https://arxiv.org/pdf/1904.04200.pdf), [Presentación](https://indico.cern.ch/event/809820/contributions/3632625/attachments/1971084/3278910/ML4Jets_talk_barrydillon.pdf)| BB1-3|\n",
    "|     PGAE|    No supervisado| [GitHub](https://github.com/stsan9/AnomalyDetection4Jets) | BB1,2|\n",
    "| Reg. Likelihoods| No supervisado| [Github modelo](https://github.com/johannbrehmer/manifold-flow)| R&D|\n",
    "| UCluster|   No supervisado| [Github](https://github.com/ViniciusMikuni/UCluster), [Artículo](https://arxiv.org/pdf/2010.07106.pdf) | BB2,3|\n",
    "|   CWoLa|Débilmente supervisado| [GitHub](https://github.com/Jackadsa/CWoLa-Hunting/tree/tf2/LHCO-code)| BB1,2|\n",
    "|CWoLa AE Compare|Débilmente/No supervisado| [Artículo](https://arxiv.org/pdf/2104.02092.pdf) | R&D|\n",
    "|Tag N' Train|Débilmente supervisado| [GitHub](https://github.com/OzAmram/TagNTrain), [Artículo](https://arxiv.org/pdf/2002.12376.pdf), [Presentación](https://indico.cern.ch/event/809820/contributions/3632634/attachments/1970254/3277173/TagNTrain_ML4Jets.pdf) | BB1-3|\n",
    "|   SALAD|Débilmente supervisado| [GitHub](https://github.com/bnachman/DCTRHunting), [Artículo](https://arxiv.org/abs/2001.05001) | R&D|\n",
    "|SA-CWoLa|Débilmente supervisado| [GitHub](https://github.com/bnachman/DCTRHunting), [Artículo](https://arxiv.org/pdf/2009.02205.pdf)| R&D|\n",
    "|Deep Ensemble|Semi-supervisado| [GitHub](https://github.com/FFFreitas/Deep-Ensemble-Anomaly-Detection)| BB1|\n",
    "| Factorized Topics|Semi-supervisado| [GitHub](https://github.com/nilais/factorized-topic-modeling)| R&D|\n",
    "|    QUAK|Semi-supervisado| [Artículo](https://arxiv.org/abs/2011.03550) | BB1-3|\n",
    "|    LSTM|Semi-supervisado| - | BB1-3|\n",
    "```\n",
    "El rendimiento de los participantes se puede comparar únicamente a través de los resultados obtenidos. Sin embargo, los participantes analizaron diferentes conjuntos de datos, no todos reportaron un valor p, las masas de las partículas y el número de eventos de señal, y algunos resultados fueron reportados sin error. Además, los reportes referentes al rendimiento del modelo se hicieron en distintos formatos, de acuerdo al método utilizado. Por lo tanto, la comparación directa de los algoritmos es complicada.\n",
    "\n",
    "Uno de los objetivos principales de este trabajo es comparar directamente algunos modelos participantes de las LHCO 2020. Para ello, es necesario poder reproducir el resultado de dichos modelos. Estos deben cumplir múltiples de los requisitos para hacer investigación reproducible, explicados en la {numref}`rpd-investigacion`, para asegurar que se pueda obtener el resultado de los modelos en un tiempo adecuado para el desarrollo de este trabajo. \n",
    "\n",
    "A continuación, se hablará del análisis de los algoritmos participantes a nivel de la reproducibilidad de sus resultados y se explicarán los modelos a comparar en este trabajo.\n",
    "\n",
    "(alglhco-rep)=\n",
    "## Reproducibilidad\n",
    "Para escoger los algoritmos a comparar, se hizo una revisión extensiva de la información proporcionada por los participantes mencionados en la {numref}`lhc-participantes`. Como se explica en la {numref}`rpd-investigacion`, para poder reproducir resultados en este contexto es necesario, principalmente, que se encuentre pública la información sobre el pre-procesamiento de los datos, el código del modelo, instrucciones para utilizarlo, información del entorno computacional y licencia. Un resumen de la información proporcionada por cada participante se encuentra en la {numref}`alglhc-participantesrep`,\n",
    "\n",
    "```{table} Información disponible de cada participante de las LHCO 2020\n",
    ":name: alglhc-participantesrep\n",
    "\n",
    "| Nombre | Pre-procesamiento | Código| Instrucciones | Entorno| Licencia|\n",
    "|:------:|:-----------------:|:-----:|:-------------:|:------:|:-------:|\n",
    "| VRNN   |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |- |- |\n",
    "| ANODE  |- |- |- |- |- |\n",
    "| BuHuLaSpa|- |$\\checkmark$ |- |- |- |\n",
    "| GAN-AE |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |- |\n",
    "| GIS    |- |- |- |- |- |\n",
    "|  LDA   |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |- |\n",
    "|  PGAE  |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |- |\n",
    "| Reg. Likelihoods|- |- |- |- |- |\n",
    "|UCluster|$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |\n",
    "| CWoLa  |- |$\\checkmark$ |- |- |- |\n",
    "|CWoLa AE Compare|- |- | |- |- |\n",
    "|Tag N' Train|$\\checkmark$ |$\\checkmark$ |- |$\\checkmark$ |- |\n",
    "| SALAD  |- |$\\checkmark$ |- |$\\checkmark$ |- |\n",
    "|SA-CWoLa|- |$\\checkmark$ |- |$\\checkmark$ |- |\n",
    "|Deep Ensemble|- |$\\checkmark$ |$\\checkmark$ |$\\checkmark$ |- |\n",
    "|Factorized Topics|- |$\\checkmark$ |- |- |$\\checkmark$ |\n",
    "| QUAK   |- |- |- |- |- |\n",
    "| LSTM   | - |- |- |- |- |- |\n",
    "```\n",
    "Un resumen de general de la información proporcionada por todos los algoritmos se encuentra en la {numref}`alglhco-repfigure`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from myst_nb import glue\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "plt.rc('axes', labelsize=12)    # fontsize of the x and y labels\n",
    "plt.rc('xtick', labelsize=10)    # fontsize of the tick labels\n",
    "\n",
    "datos = {'Pre-procesamiento':6, 'Código':12, 'Instrucciones':6, 'Entorno':8, 'Licencia':2}\n",
    "items = list(datos.keys())\n",
    "valores = list(datos.values())\n",
    "colores = ['darkorange', 'crimson', 'green', 'blue', 'purple']\n",
    "\n",
    "fig = plt.figure(figsize = (9, 6), facecolor='white')\n",
    " \n",
    "# creating the bar plot\n",
    "plt.bar(items, valores, color = colores,width = 0.6)\n",
    "plt.xlabel(\"Información disponible\")\n",
    "plt.ylabel(\"Nro. de participantes\")\n",
    "plt.title(\"Reproducibilidad de los algoritmos de las LHCO 2020\")\n",
    "plt.ylim([0,18])\n",
    "\n",
    "plt.savefig('./../../figuras/alglhco-repfig.png', bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/alglhco-repfigure.png\n",
    "---\n",
    "width: 500px\n",
    "name: alglhco-repfigure\n",
    "---\n",
    "Resumen de la reproducibilidad de los participantes de las LHCO 2020.\n",
    "```\n",
    "En la {numref}`alglhco-repfigure` se observa que pocos algoritmos participantes poseen información pública para poder reproducir sus resultados, lo que inmediatamente limita las opciones de modelos a utilizar en este trabajo. De acuerdo a la {numref}`alglhc-participantesrep`, de los 18 participantes, sólo *UCluster* cumple con todas las características. *GAN-AE*, *LDA*  y *PGAE* cumplen con cuatro de las cinco características. Para este trabajo se escogieron ***UCluster*** y ***GAN-AE*** debido a la simplicidad de la información proporcionada. Los algoritmos se explicarán siguiendo {cite}`Kasieczka_2021`.\n",
    "\n",
    "(alglhco-ucluster)=\n",
    "## UCluster\n",
    "UCluster (Unsupervised Clustering){cite}`Mikuni_2021` es un método que reduce la dimensionalidad de los datos utilizando una red neuronal. El objetivo es retener las propiedades principales del evento de colisión, agrupando puntos con características similares que se encuentran inmersos en este espacio. El método es independiente de la arquitectura de la red neuronal. \n",
    "\n",
    "Para crear la representación reducida de los datos (o encaje), se hace una *clasificación de masa de jet por partícula*, es decir, a cada partícula perteneciente a un jet se le asigna una etiqueta proporcional a la masa del jet al que pertenece. Estas etiquetas se crean definiendo 20 intervalos equidistantes entre 10 y 1000 GeV. \n",
    "\n",
    "En particular, el modelo debe aprender la masa del jet al que la partícula pertenece y cuáles partículas pertenecen al mismo jet. El algoritmo utiliza las primeras 100 partículas asociadas a los dos jets más masivos de cada evento y consta de dos tareas: una de clasificación y otra de agrupamiento. La función de pérdida conjunta es:\n",
    "\n",
    "$$\n",
    "    L = L_{focal} + \\beta L_{cluster}\n",
    "$$ (loss-ucluster)\n",
    "\n",
    "Un valor de $\\beta=10$ se utiliza para darle a las componentes el mismo orden de magnitud relativo. $L_{focal}$ hace referencia a la función de pérdida focal, que es comúnmente utilizada para clasificar datos con etiquetas altamente desbalanceadas{cite}`Kasieczka_2021`.\n",
    "\n",
    "$$\n",
    "    L_{focal}=-\\frac{1}{N}\\sum_j^N\\sum_m^M y_{j,m}(1-p_{\\theta,m}(x_j))^\\gamma \\log(p_{\\theta,m}(x_j))\n",
    "$$ (focal-loss)\n",
    "\n",
    "donde $p_{\\theta,m}(x_j)$ es la confianza de la red para el evento $x_j$, con parámetros entrenables $\\theta$, de ser clasificado como clase $m$. $y_{j,m}$ es 1 si la clase $m$ es correctamente asignada al evento $x_j$ y 0 de otra forma. Para las LHCO 2020, los participantes fijaron el parámetro $\\gamma=2$.\n",
    "\n",
    "La función de pérdida del agrupamiento fue definida como,\n",
    "\n",
    "$$\n",
    "    L_{cluster}=\\frac{1}{N}\\sum_k^K\\sum_j^N\\|f_\\theta(x_j)-\\mu_k\\|^2\\pi_{jk}.\n",
    "$$ (cluster-loss)\n",
    "\n",
    "La distancia entre el evento $x_j$ y el centroide $\\mu_k$ se calcula en el espacio de encaje $f_\\theta$, creado por la clasificación. $\\pi_{jk}$ pesa la importancia de cada evento para el objetivo de agrupación y está definido como:\n",
    "\n",
    "$$\n",
    "    \\pi_{jk}=\\frac{e^{-\\alpha\\|f_\\theta(x_j)-\\mu_k\\|}}{\\sum_{k'}e^{-\\alpha\\|f_\\theta(x_j)-\\mu_k\\|}}\n",
    "$$ (peso-clusterloss)\n",
    "\n",
    "con el hiperparámetro $\\alpha$.\n",
    "\n",
    "El valor inicial de los centroides se obtiene utilizando el algoritmo K-means, para luego realizar el entrenamiento utilizando la función de pérdida conjunta en la ecuación {eq}`loss-ucluster`. \n",
    "\n",
    "Como se mencionó anteriormente, el modelo es libre de la arquitectura de la red neuronal. Sin embargo, la implementación utilizada en las LHCO 2020 utiliza ABCNet, una red basada en grafos donde cada partícula reconstruida es un nodo del grafo.\n",
    "\n",
    "(alglhco-ganae)=\n",
    "## GAN-AE\n",
    "El método GAN-AE intenta asociar un discriminante y un codificador automático como una red generativa antagónica siguiendo los pasos a continuación:\n",
    "\n",
    "La **red discriminativa** es un perceptrón multicapas (MLP). Inicialmente es entrenado utilizando la entropía cruzada binaria (ec.{eq}`binary-crossentropy`) en una muestra mezclada de eventos reconstruidos y originales, con el objetivo de exponer las debilidades del codificador automático.\n",
    "\n",
    "El **codificador automático** es entrenado utilizando una función de pérdida que combina la reconstrucción del error (en este caso, la distancia euclídea media (MED, por sus siglas en inglés) entre la entrada y la salida) y la entropía binaria cruzada.\n",
    "\n",
    "$$  \n",
    "    \\mathcal{L}_{AE} = \\mathcal{L}_{BC}+\\epsilon\\times\\text{MED}+\\alpha\\times\\text{DisCo}\n",
    "$$ (loss-ae)\n",
    "\n",
    "donde $\\epsilon$ y $\\alpha$ son hiperparámetros para balancear los pesos de cada término y $\\text{DisCo}$ es la correlación de distancia, para decorrelacionar el error de reconstrucción de la masa invariante. En este caso, $\\mathcal{L}_{BC}$ se evalúa dando eventos reconstruidos a la red discriminativa, pero esta vez con la etiqueta \"equivocada\", con el objetivo de engañarla.\n",
    "\n",
    "Por último, se evalúa el codificador automático utilizando una *figura de mérito*:\n",
    "\n",
    "$$\n",
    "    \\text{FoM}=\\text{MED}+(1-\\text{Media salida MLP}).\n",
    "$$ (fom)\n",
    "\n",
    "El término $1-\\text{Media salida MLP}$ es cercano a cero a medida que el codificador automático engaña mejor al MLP.\n",
    "\n",
    "Estos tres pasos se repiten en un bucle y una vez que el codificador automático ha sido entrenado se descarta la red discriminativa. Una vez descartada, el codificador automático utiliza las MED como característica discriminativa.\n",
    "\n",
    "Los participantes utilizaron el método descrito anteriormente en conjunto con *BumpHunter*, un algoritmo que compara la distribución de los datos con datos de referencia y evalúa el valor p y la significancia de cualquier desviación. Sin embargo, la implementación en este trabajo se limita al uso del algoritmo GAN-AE, que es la parte de clasificación binaria de este método."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
