{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(comp)=\n",
    "# Comparación de algoritmos\n",
    "El rendimiento de los algoritmos utilizados anteriormente no puede ser comparado directamente mediante las ditribuciones de las predicciones para cada variable. Como vimos en la sección anterior, un algoritmo puede parecer ajustar muy bien a los datos en una variable pero no en otra. Por esto, utilizamos las métricas explicadas en la {numref}`met` para comparar directamente el rendimiento de los algoritmos.\n",
    "\n",
    "En esta sección se compararán los algoritmos utilizados en la sección anterior, agregando UCluster y GAN-AE. \n",
    "\n",
    "Usualmente, del conjunto R&D se obtendrían las métricas de rendimiento con el fin de configurar los modelos para que realicen la mejor clasificación posible. Sin embargo, en el caso de este trabajo, comparamos el rendimiento de los algoritmos al clasificar un subconjunto del conjunto utilizado para entrenamiento y al clasificar un conjunto ligeramente distinto, en este caso el conjunto R&D y BB1, respectivamente.\n",
    "\n",
    "Los resultados presentados en esta sección se obtuvieron utilizando el pipeline de `benchtools`.\n",
    "\n",
    "(comp-RnD)=\n",
    "## Conjunto R&D\n",
    "En la sección anterior, se mostraron las distribuciones predichas de algunas variables utilizando el conjunto R&D con el objetivo de tener una idea general de cómo están clasificando los algoritmos y para poder asociar esta clasificación a las métricas que se mostrarán a continuación.\n",
    "\n",
    "Es necesario acotar que la clasificación realizada por los algoritmos de las LHCO 2020 para el conjunto R&D no se realiza utilizando exactamente el mismo subconjunto de datos utilizado con los demás algoritmos. Aunque es el mismo conjunto de datos, la distribución de los subconjuntos de entrenamiento y prueba varían para los algoritmos de las olimpiadas de acuerdo al código publicado. Sin embargo, la proporción de datos es la misma para todos los métodos.\n",
    "### Métricas numéricas\n",
    "En la {numref}`comp-metricas-num-RnD` se observa una comparación visual de las métricas numéricas: *exactitud balanceada*, *precisión*, *recuperación* y *puntaje f1*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "from benchtools.src.plotools import image_grid\n",
    "\n",
    "# Definimos el path de las imagenes\n",
    "PATH_FIGURES = '../../figuras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-balancedacc-RnD.png','../../figuras/comp-precision-RnD.png',\n",
    "                '../../figuras/comp-recall-RnD.png','../../figuras/comp-f1score-RnD.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-num-RnD', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-num-RnD.png\n",
    "---\n",
    "width: 80%\n",
    "name: comp-metricas-num-RnD\n",
    "---\n",
    "Diagramas de barras de las métricas numéricas obtenidas utilizando el pipeline de `benchtools` para el conjunto R&D. De izquierda a derecha, en la fila superior: exactitud balanceada y precisión. En la fila inferior: recuperación y puntaje f1.\n",
    "```\n",
    "Todos los modelos obtuvieron un puntaje de exactitud balanceada mayor a 70%, lo que se considera alto. Sin embargo, observamos que la precisión y la recuperación varía entre los clasificadores. \n",
    "\n",
    "Los modelos supervisados QDA, GB y RFC obtuvieron altos puntajes de precisión pero bajos puntajes de recuperación. Esto significa que los algoritmos clasifican pocos eventos como señal, pero estas clasificaciones son mayormente correctas. En contraste, el modelo MLP obtuvo un alto puntaje de precisión y recuperación. \n",
    "\n",
    "Por otra parte el modelos de TensorFlow, obtuvo un menor puntaje de precisión pero el mayor puntaje de recuperación. Es decir, clasifica mas eventos como señal, clasificando eventos de fondo incorrectamente, pero logra clasificar la mayoría de los eventos de señal con la etiqueta correcta.\n",
    "\n",
    "Los modelos no supervisados KMeans, UCluster y GAN-AE son los modelos con menor precisión pero mayor recuperación. Es decir, están etiquetando una mayor cantidad de eventos de fondo incorrectamente como señal, pero entre los eventos etiquetados como señal se encuentra la mayor parte de los eventos de señal real. \n",
    "\n",
    "La media armónica de estas dos métricas se observa en el gráfico del puntaje f1, donde en general los modelos supervisados obtuvieron puntajes más altos que los modelos no supervisados.\n",
    "\n",
    "El mayor puntaje f1 fue obtenido por MLP. Sin embargo, el mayor puntaje de precisión lo obtuvo RFC y el mayor puntaje de recuperación lo obtuvo el modelo de TensorFlow, que también obtuvo el mayor puntaje de exactitud balanceada.\n",
    "\n",
    "Los menores puntajes fueron obtenidos por UCluster, con la menor precisión y menor puntaje f1, y por GBC, con el menor puntaje de exactitud balanceada y recuperación. \n",
    "\n",
    "Un resumen de los valores numéricos obtenidos se encuentran en la {numref}`comp-metricasnumericas-RnD`.\n",
    "\n",
    "```{table} Métricas numéricas obtenidas con el pipeline de *benchtools* para el conjunto R&D.\n",
    ":name: comp-metricasnumericas-RnD\n",
    "\n",
    "| Classifier                    |   Balanced accuracy |   Precision |   Recall |   F1 score |\n",
    "|:-----------------------------:|:-------------------:|:-----------:|:--------:|:----------:|\n",
    "| TensorflowClassifier          |            0.9076   |   0.5033    | 0.9044   |  0.6467    |\n",
    "| RandomForestClassifier        |            0.8127   |   0.8556    | 0.6362   |  0.7298    |\n",
    "| GradientBoostingClassifier    |            0.7930   |   0.8145    | 0.5997   |  0.6908    |\n",
    "| QuadraticDiscriminantAnalysis |            0.8146   |   0.6973    | 0.6578   |  0.6770    |\n",
    "| MLPClassifier                 |            0.8623   |   0.8391    | 0.7388   |  0.7858    |\n",
    "| KMeans                        |            0.7934   |   0.2551    | 0.8288   |  0.3901    |\n",
    "| GAN-AE                        |            0.7950   |   0.3962    | 0.8431   |  0.5391    |\n",
    "| UCluster                      |            0.8073   |   0.0308    | 0.8921   |  0.0595    |\n",
    "\n",
    "```\n",
    "### Métricas gráficas\n",
    "Las métricas gráficas obtenidas con el pipeline de `benchtools` son la eficiencia de señal vs. rechazo de fondo, la ROC inversa, la curva precisión recuperación y la mejora significativa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-rejection-RnD.png','../../figuras/comp-inverseroc-RnD.png',\n",
    "                '../../figuras/comp-precisionrecall-RnD.png','../../figuras/comp-significance-RnD.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-graf-RnD', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a todas las métricas gráficas, el modelo MLP es el que tiene un mejor rendimiento, con un AUC de 0.975 y una precisión promedio de 0.862 ({numref}`comp-metricas-graf-RnD`).\n",
    "```{figure} ../../figuras/comp-metricas-graf-RnD.png\n",
    "---\n",
    "width: 90%\n",
    "name: comp-metricas-graf-RnD\n",
    "---\n",
    "Metricas gráficas para la clasificación del conjunto R&D. De izquierda derecha, en la fila superior: eficiencia de señal vs. rechazo de fondo, ROC inversa, y en la fila inferior: precisión-recuperación y mejora significativa.\n",
    "```\n",
    "Del gráfico de eficiencia de señal vs. rechazo de fondo y del gráfico de precisión-recuperación, observamos que el clasificador de TensorFlow se encuentra en segundo lugar con un AUC de 0.969 y una precisión media de 0.832. Sin embargo, en los gráficos de la curva ROC inversa y de mejora significativa, no es evidente cuál da un mejor resultado entre el clasificador de TensorFlow y RFC. \n",
    "\n",
    "Seguido de estos modelos, se encuentran GBC y QDA en todas las métricas.\n",
    "\n",
    "Por último, las curvas de los modelos UCluster y GAN-AE se cruzan múltiples veces en los gráficos de eficiencia de señal vs. rechazo de fondo, la ROC inversa y la mejora significativa, por lo que es difícil determinar cuál de los algoritmos da un mejor resultado. De acuerdo al AUC, GAN-AE da un mejor resultado que UCluster. Sin embargo, según la curva de precisión-recuperación, GAN-AE tiene un mejor resultado, con una precisión media de 0.521, mientras que la clasificación de UCluster da una precisión promedio de 0.130.\n",
    "\n",
    "Por último, KMeans obtuvo el menor AUC y la curva de este modelo se encuentra por debajo de todos los demás modelos en todos los gráficos excepto el de precisión-recuperación. De acuerdo a este gráfico, KMeans obtiene un mejor resultado, con una precisión promedio de 0.130.\n",
    "\n",
    "En el caso de este trabajo, es de interés conocer qué tan bien funcionan los algoritmos para separar señal y fondo en conjuntos de datos desconocidos para los modelos, con algunas variaciones en las distribuciones, como lo es el conjunto BB1.\n",
    "\n",
    "(comp-BB1)=\n",
    "## Conjunto BB1\n",
    "A diferencia de las predicciones realizadas con el cojunto R&D, las predicciones para el conjunto BB1 se hacen sobre todos los eventos, utilizando los modelos entrenados previamente con el 70% del conjunto R&D. Las métricas obtenidas en este apartado proveen una medida más cercana al verdadero rendimiento de los algoritmos para detectar anomalías.\n",
    "\n",
    "### Métricas numéricas\n",
    "En la {numref}`comp-metricas-num-BB1` vemos que las métricas varían con respecto a lo obtenido para el conjunto R&D. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-balancedacc-BB1.png','../../figuras/comp-precision-BB1.png',\n",
    "                '../../figuras/comp-recall-BB1.png','../../figuras/comp-f1score-BB1.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-num-BB1', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-num-BB1.png\n",
    "---\n",
    "width: 100%\n",
    "name: comp-metricas-num-BB1\n",
    "---\n",
    "Diagramas de barras de las métricas numéricas obtenidas utilizando el pipeline de `benchtools` para el conjunto BB1. De izquierda a derecha, en la fila superior: exactitud balanceada y precisión. En la fila inferior: recuperación y puntaje f1.\n",
    "```\n",
    "La exactitud balanceada sigue siendo alta para todos los algoritmos.\n",
    "\n",
    "La precisión disminuyó notablemente para todos los modelos. En este conjunto, la mayor precisión fue lograda por RFC con un 3% de precisión, contrario a la precisión obtenida para el conjunto R&D, de 86%. Esto implica que los algoritmos clasifican más eventos de fondo incorrectamente, o menos eventos de señal correctamente, en el conjunto BB1.\n",
    "\n",
    "La recuperación aumentó para los modelos GBC, GAN-AE y UClueste. Para UCluster, GAN-AE, KMeas y el clasificador de TensorFlow, la recuperación se mantuvo cercana o sobre el 80%. La baja precisión y alta recuperación indica que los modelos están clasificando una gran cantidad de eventos de fondo como señal. Sin embargo, en estos eventos clasificados como señal logran clasificar la señal real.\n",
    "\n",
    "Debido a la baja precisión, el puntaje f1 se vio afectado y disminuyó notablemente para todos los clasificadores. El clasificador con mayor puntaje es RFC, con un puntaje f1 de 0.05, mientras que en el conjunto R&D obtuvo 0.73. \n",
    "\n",
    "```{table} Métricas numéricas obtenidas con el pipeline de *benchtools* para el conjunto BB1.\n",
    ":name: comp-metricasnumericas-BB1\n",
    "\n",
    "| Classifier                    |   Balanced accuracy |   Precision |    F1 score |   Recall |\n",
    "|:-----------------------------:|:-------------------:|:-----------:|:-----------:|:--------:|\n",
    "| TensorflowClassifier          |            0.8418   | 0.0049      | 0.0096      | 0.8249   |\n",
    "| RandomForestClassifier        |            0.7005   | 0.0362      | 0.0666      | 0.4101   |\n",
    "| GradientBoostingClassifier    |            0.7164   | 0.0367      | 0.0678      | 0.4424   |\n",
    "| QuadraticDiscriminantAnalysis |            0.6894   | 0.0264      | 0.0495      | 0.3909   |\n",
    "| MLPClassifier                 |            0.8143   | 0.0028      | 0.0055      | 0.9005   |\n",
    "| KMeans                        |            0.8094   | 0.0039      | 0.0078      | 0.7854   |\n",
    "| GAN-AE                        |            0.9091   | 0.0201      | 0.0393      | 0.8752   |\n",
    "| UCluster                      |            0.8070   | 0.0002      | 0.0003      | 0.9767   |\n",
    "```\n",
    "### Métricas gráficas\n",
    "Las métricas gráficas también varían con respecto a las obtenidas utilizando el conjunto R&D. Los resultados se observan en la {numref}`comp-metricas-graf-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "lista_imagenes = ['../../figuras/comp-rejection-BB1.png','../../figuras/comp-inverseroc-BB1.png',\n",
    "                '../../figuras/comp-precisionrecall-BB1.png','../../figuras/comp-significance-BB1.png']\n",
    "image_grid(rows=2, columns=2, images=lista_imagenes, name='comp-metricas-graf-BB1', path=PATH_FIGURES, remove=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ../../figuras/comp-metricas-graf-BB1.png\n",
    "---\n",
    "width: 90%\n",
    "name: comp-metricas-graf-BB1\n",
    "---\n",
    "Metricas gráficas obtenidas para el conjunto BB1. De izquierda derecha, en la fila superior: eficiencia de señal vs. rechazo de fondo, ROC inversa, y en la fila inferior: precisión-recuperación y mejora significativa.\n",
    "```\n",
    "En todos los gráficos, es evidente que GAN-AE tiene un mejor rendimiento en este conjunto de datos. Así mismo, los clasificadores con el menor rendimiento son KMeans y UCluster.\n",
    "\n",
    "De acuerdo al gráfico de eficiencia de señal vs. rechazo de fondo, el algoritmo con mejores resultados después de GAN-AE es MLP, con un AUC de 0.953. Seguido a estos modelos, no es evidente cuál da un mejor resultado entre GBC y RFC y entre QDA y el clasificador de TensorFlow. De acuerdo al AUC, a MLP le sigue GBC, RFC, el clasificador de TensorFlow y QDA.\n",
    "\n",
    "Sin embargo, en el gráfico de ROC inversa, las curvas de los modelos GBC, QDA, MLP, RFC y el clasificador de TensorFlow se cruzan multiples veces, dificultando diferenciar cuál de los clasificadores tiene un mejor rendimiento.\n",
    "\n",
    "De la métrica de precisión-recuperación, GBC, el clasificador de TensorFlow y QDA obtuviero una mayor precisión promedio que el modelo MLP. Este mismo orden de los modelos se obtiene en el gráfico de mejora significativa."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
