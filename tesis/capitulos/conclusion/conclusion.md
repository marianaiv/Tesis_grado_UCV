# Conclusión
En el curso de este trabajo se trataron cuatros temas principales: la búsqueda de nueva física, el uso de aprendiza automático en este contexto, la comparación de algoritmos de clasificación binaria y la reproducibilidad científica. 

Desde el hallazgo del bosón de Higgs en 2012, la búsqueda de nueva física se convirtió en el eje principal de investigación del LHC. Esto representa un momento histórico importante en el área de investigación de la física de partículas, donde si bien se tienen direcciones de búsqueda, no hay una idea clara de cómo se van a hallar nuevos fenómenos. A su vez, a medida que se alcanzan mayores energías de colisión en el LHC, los datos registrados de los eventos aumentan en volumen y complejidad más rápidamente que las herramientas utilizadas para su análisis. Esto resulta en múltiples retos para la búsqueda de física BSM y el continuo estudio del modelo estándar. Sin embargo, desde antes del hallazgo del bosón de Higgs, se plantea aplicar herramientas computacionales para mejorar el análisis de los datos obtenidos en las colisiones. De hecho, el hallazgo del bosón de Higgs es ejemplo de su uso, y no hubiese sido posible sin estas herramientas. 

Múltiples herramientas computacionales se han utilizado con un sinfín de objetivos en la búsqueda de nueva física. Sin embargo, en los últimos años, ha surgido interés por el uso de aprendizaje automático para la búsqueda de nuevas partículas. En principio, es una herramienta que tiene la capacidad de aprovechar el volumen y complejidad de los datos de los experimentos de colisión para realizar búsquedas de nueva física generales o independientes de modelo, es decir, una herramienta ideal para hallar nuevos fenómenos sin buscar uno en específico. Su implementación, por otra parte, presenta sus propios retos, por lo que no se ha logrado perfeccionar una herramienta suficientemente efectiva para ser usada en las búsquedas que se realizan hoy en día. Por ello, la investigación y desarrollo de estos métodos es de gran interés, puesto que prometen mejorar las búsquedas de nuevas partículas y el análisis de los datos de los experimentos de colisión de manera general. Entre los esfuerzos para procurar el perfeccionamiento de estas herramientas, se plantearon las olimpiadas LHC 2020, para estudiar el uso de técnicas de detección de anomalías para la búsqueda de nuevas partículas en eventos simulados. Esto simboliza un paso importante, no solo en el desarrollo del aprendizaje automático, sino en las nuevas maneras de hacer ciencia de forma abierta y en comunidad. Este evento permitió el desarrollo de este trabajo, enfocado en la comparación de algoritmos de aprendizaje automático para la búsqueda de nueva física, cuyo desenlace se describe a continuación.

De acuerdo a los resultados obtenidos, los modelos implementados de `scikit-learn` y `TensorFlow` se muestran competentes en la tarea de clasificación de eventos, considerando que son implementaciones sencillas y con poco ajuste de parámetros, demostrando la gran capacidad del aprendizaje automático para la clasificación de eventos. De estos métodos, el modelo MLP obtuvo mayores puntajes en la clasificación del conjunto R&D y GBC en la clasificación del conjunto BB1. Para ambos conjuntos KMeans obtuvo los menores resultados, demostrando que el uso de aprendizaje no supervisado requiere mayor desarrollo en términos de preprocesamiento y optimización de los parámetros de los algoritmos.

De los modelos de las olimpiadas LHC 2020, GAN-AE tiene mayores puntajes que UCluster en ambos conjuntos. Incluyendo todos los modelos comparados, GAN-AE tiene el mayor puntaje de los modelos no supervisados al clasificar el conjunto R&D, pero menor puntaje que todos los modelos supervisados. Sin embargo, para el conjunto BB1, GAN-AE posee un mejor resultado en general. UCluster posee un menor puntaje en general en ambos conjuntos.

En función de lo anterior, y de los resultados obtenidos, los modelos supervisados presentan un mejor rendimiento que los no supervisados al clasificar eventos iguales a los eventos con los que fueron entrenados. Sin embargo, observamos que al clasificar un conjunto de datos con un evento de nueva física que posee partículas BSM con masas distintas, y con menor densidad de eventos de señal, un modelo no supervisado más complejo, optimizado para la detección de anomalías, puede obtener mejores resultados, lo que se relaciona con un mayor poder de generalización o una mejor aproximación a las características fundamentales del problema. En particular, un modelo no supervisado como GAN-AE, modelo que prioriza aprender la distribución del fondo, puede obtener mejores resultados en conjuntos con señales distintas que los modelos supervisados, que aprenden las distribuciones tanto del fondo como de la señal, lo que disminuye la capacidad de generalización, y limita la búsqueda de nuevas partículas.

Al realizar este trabajo se evidenció la necesidad de la investigación de variables físicas de eventos de múltiples jets que sean independientes de la masa, para aumentar la sensibilidad de los modelos a eventos con distintas masas y poder realizar realmente una búsqueda de nueva física independiente de la masa de las partículas. También es evidente que se necesita investigar las métricas existentes relacionadas al estudio del rendimiento de estos métodos, y desarrollar nuevas, para obtener una comparación más realista de las herramientas de aprendizaje automático al realizar la tarea de clasificación particular que se lleva a cabo al buscar nueva física en HEP. Como se discutió anteriormente, y de acuerdo a {cite}`valassi_2019`, las métricas que se han utilizado hasta ahora para comparar algoritmos de clasificación binaria, como la curva ROC, son de limitada relevancia para el estudio de estos métodos en la búsqueda de física BSM. Con respecto a la reproducibilidad, los resultados de ambos modelos fueron sencillos de obtener, a pesar de no tener la información completa del ambiente computacional, lo que afirma que los criterios planteados en The Turing Way son correctos y sí apuntan a las características necesarias para poder reproducir resultados en esta área de investigación. Sin embargo, al no tener la configuración exacta de UCluster, no se garantiza que el resultado obtenido en este trabajo coincida con el obtenido en {cite}`Kasieczka_2021`, lo que puede explicar su bajo rendimiento.

El desarrollo de nuevas herramientas en el ámbito de investigación científica siempre requiere consideraciones sobre sus formas de uso para asegurar que se cumplan las cuotas de reproducibilidad que requiere la ciencia. Sin embargo, hoy en día esto es aún más importante por dos razones principales: la investigación es cada vez más compleja e involucra a más personas. Es necesario que el uso de herramientas novedosas, como el aprendizaje automático para la investigación científica, se haga de manera abierta y reproducible, de forma que más personas puedan participar en la producción de conocimiento y se pueda construir sobre el conocimiento ya generado. Así como las olimpiadas LHC 2020 proporcionan datos abiertos, es esencial para el estudio de aprendizaje automático en HEP considerar la ciencia abierta y la reproducibilidad, de manera que se eliminen las limitaciones sobre qué conocimiento se puede reproducir y reusar, y poder estudiar con mayor profundidad, y seguir perfeccionando, el uso de estas herramientas en trabajos futuros. 

Para continuar estudiando el aprendizaje automático para la búsqueda de nueva física de forma abierta y reproducible, se recomienda unificar y fijar las métricas más relevantes para poder comparar directamente el rendimiento de distintos modelos de aprendizaje automático en la tarea específica de clasificación de eventos en HEP, y utilizarlas en investigaciones en comunidad, así como en estudios independientes. Además, se recomienda adoptar las practicas para hacer ciencia abierta de forma reproducible discutidas en este trabajo y planteadas en The Turing Way, ya que resultaron beneficiosas a la hora de escoger los algoritmos de las olimpiadas usados en el proyecto y durante el desarrollo de *benchtools* y del análisis en este trabajo.