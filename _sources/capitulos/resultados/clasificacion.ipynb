{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(clas)=\n",
    "# Clasificación de eventos\n",
    "Para comparar con los algoritmos de las LHCO 2020, utilizamos como base algunos algoritmos sencillos ya implementados en librerías como `scikit-learn`{cite}`scikit-learn` y uno programado usando `TensorFlow`{cite}`tensorflow2015-whitepaper`. En esta sección, se observarán algunas de las características de la clasificación realizada con estos algoritmos. Los modelos utilizados son los presentados en la {numref}`clas-alg`, explicados en la {numref}`alg`.\n",
    "\n",
    "```{table} Algoritmos utilizados para comparación\n",
    ":name: clas-alg\n",
    "\n",
    "|      Nombre                          | Implementación | Algoritmo                                        | Tipo          |\n",
    "|:------------------------------------:|:--------------:|:------------------------------------------------:|:-------------:|\n",
    "|Random Forest Classifier (RFC)        | `scikit-learn` | [Bosque aleatorio](alg-bosques)                  |Supervisado    | \n",
    "|Gradient Boosting Classifier (GBC)    | `scikit-learn` | [Potenciación del gradiente](alg-gbc)            |Supervisado    | \n",
    "|Quadratic Discriminant Analysis (QDA) | `scikit-learn` | [Análisis de discriminante cuadrático](alg-qda)  |Supervisado    | \n",
    "|MLP Classifier                        | `scikit-learn` | [Red neuronal](alg-neural)                       |Supervisado    | \n",
    "|Tensorflow Classifier                 | `TensorFlow`   | [Red neuronal](alg-neural)                       |Supervisado    | \n",
    "| KMeans                               | `scikit-learn` | [K-means](alg-kmeans)                            |No supervisado | \n",
    "```\n",
    "\n",
    "Para el entrenamiento de los modelos y realizar las predicciones se utilizaron las variables descritas en la {numref}`bench-variables`, a excepción de las variables de masa ($m_{jj}$, $m\\_{j_1}$ y $m\\_{j_2}$), con el fin de intentar una clasificación libre de modelo en lo que respecta a la masa de las partículas.\n",
    "\n",
    "(clas-RnD)=\n",
    "## Conjunto R&D\n",
    "Los datos del conjunto R&D se dividieron en conjuntos mutuamente excluyentes: 70% en un conjunto de entrenamiento y 30% en uno de prueba. A continuación, se mostrará la importancia de las variables para la clasificación según RFC y GBC y se observarán las distribuciones de los eventos clasificados para algunas variables, utilizando el conjunto de prueba.\n",
    "\n",
    "### Importancia de las características\n",
    "De los modelos en la {numref}`clas-alg`, RFC y GBC permiten conocer cuáles de las variables de los eventos fueron las más relevantes para discriminar entre clases. Estos algoritmos asignan puntajes a las variables de acuerdo a su importancia para la clasificación. Un gráfico de estos puntajes se presenta en la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "source": [
    "A continuación, realizaremos el entrenamiento de los modelos y la clasificación de los datos de prueba. Las celdas siguientes preparan los datos, entrenan los modelos y realizan la clasificación utilizando funciones de `benchtools`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Importamos las librerías principales\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "import os.path\n",
    "\n",
    "# De scikit-learn importamos herramientas\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Y los clasificadores\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Lo necesario para construir el modelo de tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Funciones de benchtools\n",
    "from benchtools.src.plotools import pred_test_hist, image_grid\n",
    "from benchtools.src.clustering import build_features\n",
    "from benchtools.src.datatools import separate_data\n",
    "from benchtools.scripts.run import TensorflowClassifier, training, evaluate\n",
    "from benchtools.src.metrictools import rejection_plot, precision_recall_plot\n",
    "\n",
    "# Definimos semillas para la reproducibilidad\n",
    "tf.random.set_seed(125)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Datos a utilizar\n",
    "path_data = \"../../../datos/events_anomalydetection.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A file with that name already exists\n"
     ]
    }
   ],
   "source": [
    "# Esta celda se corre una vez para pre-procesar los datos\n",
    "# Una vez que el archivo existe no vuelve a correr\n",
    "build_features(path_data=path_data, nbatch=11, outname='RnD-1100000', outdir='../../../datos/', chunksize=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda preparamos los datos para utilizar los algoritmos\n",
    "# Separamos los datos en conjuntos de entrenamiento y prueba\n",
    "df_RnD = pd.read_csv('../../../datos/RnD-1100000.csv')\n",
    "X, y = separate_data(df_RnD, standarize=False)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1, stratify=y) # 70% training y 30% test\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_train_m = X_train.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "X_test_m = X_test.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas de los conjuntos de entrenamiento y prueba\n",
    "X_train.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "X_test.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Listamos los clasificadores a utilizar\n",
    "# En conjunto con el scaler\n",
    "classifiers = [(MinMaxScaler(feature_range=(-1,1)), TensorflowClassifier(input_shape = [X_train.shape[1]])),\n",
    "                (StandardScaler(), RandomForestClassifier(random_state=1)),\n",
    "                (RobustScaler(), GradientBoostingClassifier(random_state=4)),\n",
    "                (RobustScaler(), QuadraticDiscriminantAnalysis()), \n",
    "                (StandardScaler(), MLPClassifier(random_state=7)),\n",
    "                (StandardScaler(), KMeans(n_clusters=2, random_state=15))\n",
    "                ]\n",
    "# Listamos los nombres para los plots\n",
    "nombres_modelos = ['TensorFlow', 'RFC', 'GBC', 'QDA', 'MLP', 'KMeans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Con esta función entrenamos los modelos\n",
    "# Solo hace falta correrla una vez\n",
    "#training(X_train, y_train, classifiers, '../../../datos', 'log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [02:05<00:00, 20.99s/it]\n"
     ]
    }
   ],
   "source": [
    "# En esta celda cargamos los modelos entrenados\n",
    "models = []\n",
    "\n",
    "# Cargamos el algoritmo entrenado de tensorflow\n",
    "tf_model = load_model(os.path.join('../../../datos','tf_model_{}.h5'.format('log')))\n",
    "models.append(('TensorflowClassifier', tf_model))\n",
    "\n",
    "# Cargamos los algoritmos entrenados de scikit-learn\n",
    "with open(os.path.join('../../../datos',\"sklearn_models_{}.pckl\".format('log')), \"rb\") as f:\n",
    "    while True:\n",
    "        try:\n",
    "            models.append(pickle.load(f))\n",
    "        except EOFError:\n",
    "            break\n",
    "\n",
    "# Evaluamos\n",
    "clfs = evaluate(X_test, y_test, models ,train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las características más importantes para los modelos\n",
    "\n",
    "# Obtenemos las características más importantes\n",
    "# models[x][y] : x = 1(random forest), 2(gradient boosting); y = 0(nombre del modelo), 1(modelo entrenado) \n",
    "fi_rf = models[1][1].steps[1][1].feature_importances_.tolist()\n",
    "fi_gb = models[2][1].steps[1][1].feature_importances_.tolist()\n",
    "\n",
    "# Redondeamos los puntajes\n",
    "weights = [fi_rf, fi_gb]\n",
    "weights = [[ round(elem, 3) for elem in weight ] for weight in weights]\n",
    "# Obtenemos los nombres de los modelos\n",
    "names_fi = ['RFC', 'GBC']\n",
    "# Obtenemos los nombres de las características\n",
    "#features = X_train.columns.tolist()\n",
    "#print(features)\n",
    "# Los cambiamos por los nombres con notación bonita\n",
    "features = [r'$pT_{j1}$', r'$\\eta_{j1}$', r'$\\phi_{j1}$', r'$E_{j1}$', r'$\\tau_{21,j1}$', 'n. hadrones j1', r'$pT_{j2}$', \n",
    "            r'$\\eta_{j2}$', r'$\\phi_{j2}$', r'$E_{j2}$', r'$\\tau_{21,j2}$', 'n. hadrones j2', r'$\\Delta R$', 'n. hadrones']\n",
    "\n",
    "# Juntamos los puntajes con las características en tuplas\n",
    "importance = {}\n",
    "ii = 0\n",
    "for weight in weights:\n",
    "    f_i = list(zip(features, weight))\n",
    "    importance[names_fi[ii]] = f_i\n",
    "    ii +=1\n",
    "\n",
    "# Graficamos en un bucle \n",
    "colors=['darkorange', 'green']\n",
    "lista_images = []\n",
    "ii = 0\n",
    "\n",
    "for name, scores in importance.items():\n",
    "\n",
    "    # Ordenamos de menor a mayor\n",
    "    scores.sort(key=lambda x: x[1], reverse=False) \n",
    "\n",
    "    # Salvamos los nombres y su puntaje separados\n",
    "    # y revertimos las tuplas para tener de mayor a menor puntaje \n",
    "    features = list(zip(*scores))[0]\n",
    "    score = list(zip(*scores))[1]\n",
    "    x_pos = np.arange(len(features))\n",
    "\n",
    "    # Graficamos\n",
    "    fig = plt.figure(facecolor='white')\n",
    "    plt.barh(x_pos, score,align='center', color = colors[ii])\n",
    "    plt.yticks(x_pos, features) \n",
    "    plt.xlabel('Importancia de las características')\n",
    "    plt.title('Importancia de las características: {}'.format(name))\n",
    "    filename = '../../figuras/{}-feature-importance.png'.format(name)\n",
    "    lista_images.append(filename)\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close('all')\n",
    "    ii += 1\n",
    "    \n",
    "image_grid(rows=1, columns=2, images=lista_images, name='clas-feature-imp', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-feature-imp.png\n",
    "---\n",
    "name: clas-feature-imp\n",
    "width: 80%\n",
    "---\n",
    "Importancia de las variables utilizadas en el entrenamiento realizado con el conjunto de datos R&D según RFC (izquierda) y GBC (derecha).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las características más importantes para ambos clasificadores son la variable de subestructura $\\tau_{21}$, el $pT$ de los jets y el número de hadrones de los eventos, y las menos importantes son $\\eta$ y $\\phi$. Esto indica que las variables con mayor separación entre las distribuciones de señal y fondo, como se puede ver en la {numref}`datospp-vardiff-RnD` del capítulo anterior, son más relevante en el aprendizaje de los modelos. \n",
    "### Distribuciones de eventos clasificados\n",
    "Con la clasificación realizada por los distintos modelos, podemos graficar las distribuciones resultantes de los eventos clasificados como señal o fondo y compararlas con las distribuciones de los datos simulados utilizados como entrada. En la {numref}`clas-variables-dist` se encuentran las distribuciones de los datos simulados y de los datos clasificados para las variables más importantes según la {numref}`clas-feature-imp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "nombres=[r'$pT$ del jet secundario', r'$\\tau_{21}$ del jet principal', 'nro. hadrones']\n",
    "xaxis=[r'$pT$', r'$\\tau_{21}$', 'nro. hadrones']\n",
    "\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre , nombrex in zip(variables, nombres, xaxis):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombrex, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' R&D')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist.png\n",
    "---\n",
    "name: clas-variables-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución de los datos simulados y la clasificación para algunas de las variables más importantes usando el conjunto prueba R&D. Cada fila de imágenes representa un clasificador. De arriba a abajo: clasificador de TensorFlow, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentran las distribuciones de $p_T$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "En general, las distribuciones obtenidas de la clasificación realizada por los modelos son similare a las de los datos simulados. La distinción entre señal y fondo es lograda de forma más precisa por los modelos supervisados, porque poseen más información sobre los eventos en el momento del aprendizaje, puesto que aprenden utilizando la etiqueta de cada evento. \n",
    "\n",
    "Particularmente, vemos que el clasificador de Tensorflow está subestimando la cantidad de eventos de señal en todas las variables. Esto se evidencia en los picos de las distribuciones de las variables, donde se observa que las distribuciones de los eventos clasificados como señal poseen menor frecuencia de eventos que la señal simulada utilizada. Al contrario, se observa que RFC, GBC y QDA sobreestiman la cantidad de eventos de señal, puesto que en los picos de señal en cada gráfico se observa que las distribuciones de los eventos clasificados como señal son más frecuentes que los de la señal en las muestras emuladas. El clasificador MLP parece clasificar con mayor precisión, ya que la señal clasificada es más cercana a la simulada. El único modelo no supervisado, Kmeans, logra separar algunos eventos de señal según los gráficos de $pT$ y de $\\tau_{12}$, pero en el gráfico de número de hadrones vemos que no logra diferenciar entre clases. Esto indica que los eventos de señal predicho están contaminados por eventos de fondo.\n",
    "\n",
    "Al graficar algunas de las variables con menor importancia según la {numref}`clas-feature-imp`, en la {numref}`clas-variables-noimp-dist`, también se evidencia que el clasificador de TensorFlow está subestimando la cantidad de eventos de señal y que RFC, GBC y QDA sobreestiman la cantidad de eventos de señal. Como se mencionó anteriormente, el modelo MLP clasifica más precisamente, lo que también se observa en estas variables, donde las distribuciones de la clasificación son similares a las de los datos simulados. Para KMeans, se observa nuevamente que los eventos predichos como señal están contaminados por eventos de fondo, puesto que en el gráfico de $\\eta$ el modelo no distingue entre señal y fondo, y en $\\Delta R$ y $E$ los picos de las distribuciones de los eventos predichos como señal muestran menor frecuencia de eventos que las distribuciones de la señal esperada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "nombres=[r'$\\Delta R$', r'$E$ del jet principal', r'$\\eta$ del jet principal']\n",
    "xaxis=[r'$\\Delta R$', r'$E$', r'$\\eta$']\n",
    "\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre, nombrex in zip(variables, nombres, xaxis):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombrex, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' R&D')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist.png\n",
    "---\n",
    "name: clas-variables-noimp-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución de algunas de las variables menos relevantes para la clasificación. Cada fila de imágenes representa un clasificador. De arriba a abajo: clasificador de TensorFlow, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "En la {numref}`clas-masa-dist` podemos ver las distribuciones de la variable de masa invariante de acuerdo a la clasificación realizada por los modelos. Las variables de masa son comúnmente utilizadas en la búsqueda de nueva física, pero no fueron utilizadas para el entrenamiento con el objetivo de que los modelos logren búsquedas generales, independientes de las masas de las partículas. En esta variable, se observa que los modelos supervisados obtienen resultados más precisos que el modelo no supervisado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false,
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "nombres = [r'$m_{jj}$']\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre in zip(variables, nombres):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X_test.reset_index(drop=True), X_test_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombre, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' R&D')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "        \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist.png\n",
    "---\n",
    "name: clas-masa-dist\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante y la clasificación para el conjunto R&D. En la fila superior, de izquierda a derecha, las predicciones de: clasificador de TensorFlow, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "En los modelos supervisados se vuelve a notar lo discutido anteriormente; el modelo de TensorFlow subestima la cantidad de señal y los demás modelos sobreestiman la cantidad de señal. Kmeans obtiene un pico para la señal de magnitud correcta, pero con baja frecuencia, y es evidente que está clasificando eventos de fondo como señal, como se puede notar en el gráfico al observar las distribuciones de señal y fondo entre 4000 y 6000 GeV.\n",
    "\n",
    "(clas-BB1)=\n",
    "## Conjunto BB1\n",
    "El conjunto BB1 se clasifica completamente, utilizando los modelos entrenados con el 70% del conjunto R&D. Como se mencionó en capítulos anteriores, este conjunto posee una menor proporción de señal, 0.08% del conjunto es señal, y las partículas de nueva física son más masivas.\n",
    "### Distribuciones de eventos clasificados\n",
    "Las distribuciones de las variables más importantes y la clasificación realizada utilizando el conjunto BB1 se ve en la {numref}`clas-variables-dist-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 6/6 [06:01<00:00, 60.31s/it]\n"
     ]
    }
   ],
   "source": [
    "# En esta celda preparamos los datos a utilizar por los algoritmos\n",
    "# Separamos los datos variables y label\n",
    "df_BB1 = pd.read_csv('../../../datos/BB1-1000000.csv')\n",
    "X, y = separate_data(df_BB1, standarize=False)\n",
    "\n",
    "# Guardamos las columnas de masa\n",
    "X_m = X.loc[:,['m_j1', 'm_j2', 'm_jj']].copy()\n",
    "\n",
    "# Eliminamos las masas\n",
    "X.drop(['m_j1', 'm_j2', 'm_jj'], axis=1, inplace=True)\n",
    "\n",
    "# Realizamos las predicciones\n",
    "clfs = evaluate(X, y, models ,train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos algunas variables importantes\n",
    "list_images =[]\n",
    "variables=['pT_j2', 'tau_21_j1', 'n_hadrons']\n",
    "nombres=[r'$pT$ del jet secundario', r'$\\tau_{21}$ del jet principal', 'nro. hadrones']\n",
    "xaxis=[r'$pT$', r'$\\tau_{21}$', 'nro. hadrones']\n",
    "\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre, nombrex in zip(variables, nombres, xaxis):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombrex, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' BB1')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución de las variables más importantes y las distribuciones de las clasificaciones para el conjunto BB1. Cada fila de imágenes representa un clasificador. De arriba a abajo: clasificador de TensorFlow, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $pT$ del jet secundario, $\\tau_{21}$ del jet principal y el número de hadrones de los eventos.\n",
    "```\n",
    "El poder de distinción entre señal y fondo de los modelos disminuye al utilizar el conjunto BB1, lo que indica que los modelos no logran generalizar del entrenamiento realizado con el conjunto R&D a otro conjunto de datos con masas distintas para las partículas de BSM. A pesar de haber eliminado la masa para el entrenamiento de los modelos, se utilizaron variables que cambian al variar la masa de las partículas de nueva física del evento. Entre estas variables se encuentra el $pT$ de los jets, que es mayor para los jets del conjunto BB1 debido a que la partícula de nueva física es más masiva, $\\tau_{21}$, debido a que la colisión posee mayor transferencia de momento y las partículas resultantes poseen un mayor impulso, y $\\Delta R$, cuya distribución es más angosta para colisiones más energéticas. Dichas variables se encuentran entre las más importantes para realizar la clasificación, lo que puede afectar la clasificación de datos con distintas masas. La diferencia entre las variables mencionadas anteriormente para la señal en los conjuntos R&D y BB1 se encuentra en la {numref}`clas-senal-RnD-BB1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "df_RnD = pd.read_csv('../../../datos/RnD-1100000.csv')\n",
    "df_BB1 = pd.read_csv('../../../datos/BB1-1000000.csv')\n",
    "# Obtenemos los datos de señal en cada conjunto de datos\n",
    "df_RnD_sig = df_RnD.loc[df_RnD.loc[:,'label']==1]\n",
    "df_RnD_bkg = df_RnD.loc[df_RnD.loc[:,'label']==0]\n",
    "df_BB1_sig = df_BB1.loc[df_BB1.loc[:,'label']==1]\n",
    "# Graficamos\n",
    "fig = plt.figure(facecolor='white')\n",
    "ax = fig.add_subplot(1, 1, 1)    \n",
    "# Variables a graficar\n",
    "variables = ['pT_j1', 'tau_21_j1', 'deltaR_j12']\n",
    "nombres = [r'$pT$ del jet principal', r'$\\tau_{21}$ del jet principal', r'$\\Delta R$']\n",
    "xaxis = [r'$pT$', r'$\\tau_{21}$', r'$\\Delta R$']\n",
    "list_images = []\n",
    "for variable, nombre, nombrex in zip(variables,nombres, xaxis):\n",
    "    # Creamos los histogramas\n",
    "    df_RnD_sig[variable].plot.hist(bins=50, facecolor='darkorange', alpha=0.4, label='R&D', density=True)\n",
    "    df_BB1_sig[variable].plot.hist(bins=50, facecolor='darkturquoise', alpha=0.4, label='BB1', density=True)  \n",
    "    df_RnD_bkg[variable].plot.hist(bins=50, facecolor='b', alpha=0.25, label='background', density=True)\n",
    "    # Etiquetamos los ejes, colocamos título y leyenda\n",
    "    plt.xlabel(nombrex)  \n",
    "    plt.ylabel('Densidad de eventos')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Distribución de '+nombre)\n",
    "    # Guardamos la imagen\n",
    "    filename = './../../figuras/clas-senal-RnD-BB1-{}.png'.format(variable)\n",
    "    plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "    # Creamos una lista con las imagenes creadas\n",
    "    list_images.append(filename)\n",
    "    plt.close('all')\n",
    "\n",
    "# Creamos un grid de las imagenes    \n",
    "image_grid(rows=1, columns=3, images=list_images, name='clas-senal-RnD-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-senal-RnD-BB1.png\n",
    "---\n",
    "name: clas-senal-RnD-BB1\n",
    "width: 100%\n",
    "---\n",
    "Comparación de las distribuciones de señal de las variables $pT$ del jet principal, $\\tau_{21}$ del jet principal y $\\Delta R$ de los conjuntos de datos R&D y BB1.\n",
    "```\n",
    "Los resultados de la clasificación para las variables más relevantes se presentan en la {numref}`clas-variables-dist-BB1`. A nivel general, se observa que los modelos no logran realizar correctamente la clasificación de eventos de señal y que dicha clasificación se encuentra contaminada por eventos de fondo. En los gráficos de $pT$, notamos que los modelos obtienen una distribución corrida hacia la izquierda, es decir, aprendieron a clasificar como señal eventos de jets que poseen menor $pT$. Igualmente en la variable $\\tau_{21}$, si comparamos con la distribución de esta variable en la {numref}`clas-senal-RnD-BB1`, notamos que los modelos están clasificando para una distribución parecida a la del conjunto R&D. \n",
    "\n",
    "Las distribuciones de las variables menos relevantes para la clasificación se encuentran en la {numref}`clas-variables-noimp-dist-BB1`. Las distribuciones de estas variables refuerzan lo analizado anteriormente. En general, los modelos clasifican señal con un $\\Delta R$ más ancho y jets menos energéticos, similares a las variables del conjunto R&D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos las variables menos relevantes para la clasificación\n",
    "list_images =[]\n",
    "variables=['deltaR_j12', 'E_j1', 'eta_j1']\n",
    "nombres=[r'$\\Delta R$', r'$E$ del jet principal', r'$\\eta$ del jet principal']\n",
    "xaxis = [r'$\\Delta R$', r'$E$', r'$\\eta$']\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre, nombrex in zip(variables, nombres, xaxis):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombrex, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' BB1')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "\n",
    "image_grid(rows=6, columns=3, images=list_images, name='clas-variables-noimp-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-variables-noimp-dist-BB1.png\n",
    "---\n",
    "name: clas-variables-noimp-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución de los eventos simulados y de la clasificación para algunas de las variables menos relevantes del conjunto BB1. Cada fila de imágenes representa un clasificador. De arriba a abajo: clasificador de TensorFlow, RFC, GBC, QDA, MLP y KMeans. Por columna, de izquierda a derecha, se encuentras las distribuciones de $\\Delta R$, $E$ del jet principal y $\\eta$ del jet principal.\n",
    "```\n",
    "Por último, en la {numref}`clas-masa-dist-BB1`, observamos las distribuciones de masa invariante obtenidas para este conjunto de datos. Ninguno de los modelos reconstruye la distribución de la señal. Particularmente, notamos que los picos de señal están corridos hacia menores valores de masa, indicando que los modelos aprendieron a clasificar eventos con menor masa invariante, como la señal del conjunto R&D, a pesar de no haber utilizado las variables de masa en el entrenamiento y la clasificación.\n",
    "\n",
    "En todas las variables el clasificador de TensorFlow y KMeans obtienen las distribuciones menos similares a las simuladas. Los demás modelos obtuvieron resultados parecidos entre sí, pero en todos es evidente la contaminación de la clasificación de eventos de señal con fondo y viceversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [
     "remove-cell"
    ]
   },
   "outputs": [],
   "source": [
    "# En esta celda graficamos la masa invariante predicha\n",
    "list_mass_images=[]\n",
    "variables=['m_jj']\n",
    "nombres=[r'$m_{jj}$']\n",
    "for model, nombre_modelo in zip(clfs, nombres_modelos):\n",
    "    for variable, nombre in zip(variables, nombres):\n",
    "        # Obtenemos predicciones como pandas Series\n",
    "        pred = pd.Series(model.pred.flatten(), name='ypred')\n",
    "        # Obtenemos las etiquetas como pandas Serie\n",
    "        label = pd.Series(model.label, name='ytest').reset_index(drop=True)\n",
    "        # Juntamos las masas, las predicciones y las etiquetas\n",
    "        X_plot = pd.concat([X.reset_index(drop=True), X_m.reset_index(drop=True), pred, label], axis=1)\n",
    "        # Graficamos\n",
    "        fig = plt.figure(facecolor='white')\n",
    "        pred_test_hist(X_plot, variable, ypred='ypred', ytest='ytest', xlabel=nombre, ylabel='Densidad de eventos', \n",
    "                       n_bins=50, log=False)\n",
    "        plt.title('{}: distribución de '.format(nombre_modelo)+nombre+' BB1')\n",
    "        # Guardando el path de cada imagen\n",
    "        filename = os.path.join('../../figuras/','{}-{}.png'.format(model.name,variable))\n",
    "        list_mass_images.append(filename)\n",
    "        # Salvamos la imagen como png\n",
    "        plt.savefig(filename, bbox_inches='tight', facecolor=fig.get_facecolor(),edgecolor='none')\n",
    "        plt.close('all')\n",
    "        del X_plot, pred, label\n",
    "    \n",
    "image_grid(rows=2, columns=3, images=list_mass_images, name='clas-masa-dist-BB1', path='../../figuras/', remove=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{figure} ./../../figuras/clas-masa-dist-BB1.png\n",
    "---\n",
    "name: clas-masa-dist-BB1\n",
    "width: 100%\n",
    "---\n",
    "Distribución la masa invariante y la clasificación del conjunto BB1. En la fila superior, de izquierda a derecha, las predicciones de: clasificador de TensorFlow, RFC, GBC y en la fila inferior: QDA, MLP y KMeans.\n",
    "```\n",
    "Aunque la comparación de distribuciones proporciona un punto de partida para la comparación de los algoritmos, es necesario el uso de métricas (ver {numref}`met`), porque no es evidente cuál algoritmo está logrando una mejor clasificación de los conjuntos de datos."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "interpreter": {
   "hash": "be244558907c567e73a32fad5ffef5514602d6da01bb2b6b51508d7e46fcc84d"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
